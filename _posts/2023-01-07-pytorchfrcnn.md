---
title : '[OD/Pytorch] íŒŒì´í† ì¹˜ë¡œ Fast R-CNN êµ¬í˜„í•˜ê¸° ğŸ“¦'
layout: single
toc: true
toc_sticky: true
categories:
  - ODCode
---

## Pytorchë¡œ Fast R-CNN êµ¬í˜„í•˜ê¸°

ì´ë²ˆ ê¸€ì—ì„œëŠ” [gary1346aaë‹˜ì˜ github repository](https://github.com/gary1346aa/Fast-RCNN-Object-Detection-Pytorch)ì— ì˜¬ë¼ì˜¨ íŒŒì´í† ì¹˜ë¡œ êµ¬í˜„í•œ Fast RCNN ì½”ë“œë¥¼ ë‹¤ë¤„ë³´ê² ë‹¤. Fast RCNNì˜ í•µì‹¬ ì•„ì´ë””ì–´ë¥¼ ë‹¤ë£¬ ë¶€ë¶„ë“¤ì— ëŒ€í•´ì„œ ë¶„ì„í•´ë³¸ë‹¤. Fast RCNNì— ëŒ€í•œ ê°œë…ì€ ì´ì „ ê¸€ ([**ë§í¬**](https://hamin-chang.github.io/cv-objectdetection/frcnn/))ì„ ì°¸ê³ í•˜ë©´ ëœë‹¤.

### 1. RoI Pooling

![pyfrcnn1](https://user-images.githubusercontent.com/77332628/211156319-461968ae-e8ba-411c-bbde-ae9da7eaaceb.png)

ë¨¼ì € Fast RCNNì˜ í•µì‹¬ ì•„ì´ë””ì–´ì¸ RoI poolingì— ëŒ€í•´ ì‚´í´ë³´ì. ì´ì „ ê¸€ ([**ë§í¬**](https://hamin-chang.github.io/cv-objectdetection/frcnn/))ì—ì„œ ì–¸ê¸‰í–ˆë“¯ì´, RoI poolingì€ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì£¼ì…í•˜ëŠ” ì‚¬ì „ í›ˆë ¨ëœ VGG16 ëª¨ë¸ì˜ ë§ˆì§€ë§‰ max pooling layerë¥¼ ëŒ€ì²´í•´ì„œ ê³ ì •ëœ í¬ê¸°ì˜ feature mapì„ ë‹¤ìŒ fc layerì— ì „ë‹¬í•œë‹¤. RoI poolingì„ ìˆ˜í–‰í•˜ëŠ” feature mapì˜ í¬ê¸°ëŠ” 14x14x512ì´ë‹¤. ì´ ì ì„ ìƒê°í•˜ë©´ì„œ ì½”ë“œë¥¼ ì‚´í´ë³´ì.


```python
import torch.nn as nn
import numpy as np

class RoIPool(nn.Module):
  def __init__(self, output_size):
    super().__init__()
    self.maxpool = nn.AdaptiveMaxPool2d(output_size)
    self.size = output_size
  
  def forward(self, images, rois, roi_idx):
    n = rois.shape[0]  # RoIì˜ ê°œìˆ˜

    # ê³ ì •ëœ í¬ê¸°ì˜ ì…ë ¥ ë°ì´í„°ê°€ ë“¤ì–´ì˜¤ê¸° ë•Œë¬¸ì— ì „ë¶€ 14x14
    h = images.size(2)  # feature map ë†’ì´
    w = images.size(3)  # feature map ë„ˆë¹„

    # RoIì˜ ì¢Œí‘œ (x1,y1,x2,y2) í–‰ë ¬ (ìƒëŒ€ ì¢Œí‘œë¡œ ë“¤ì–´ì˜´)
    x1 = rois[:,0]
    y1 = rois[:,1]
    x2 = rois[:,2]
    y2 = rois[:,3]

    # RoIì˜ ìƒëŒ€ì¢Œí‘œë¥¼ feature mapì— ë§ê²Œ ì ˆëŒ€ì¢Œí‘œë¡œ ë³€í™˜
    x1 = np.floor(x1 * w).astype(int)
    x2 = np.ceil(x2 * w).astype(int)
    y1 = np.floor(y1 * h).astype(int)
    y2 = np.ceil(y1 * h).astype(int)
```

ìœ„ì˜ ì½”ë“œì—ì„œ RoIì˜ ì¢Œí‘œë¥¼ ë‹¤ë£¨ëŠ” ë¶€ë¶„ì´ ìˆëŠ”ë°, ì´ëŠ” ì½”ë“œì˜ ë°ì´í„°ì…‹ì´ ë¯¸ë¦¬ Selective searchë¥¼ ì´ë¯¸ì§€ì— ì ìš©í•´ì„œ RoIë¥¼ pkl í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ê³  ìˆëŠ”ë°, ì´ëŠ” ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ì—ì„œ RoIê°€ ì°¨ì§€í•˜ëŠ” ë¹„ìœ¨ í˜•ì‹ìœ¼ë¡œ ë˜ì–´ ìˆì–´ì„œ ì´ë¥¼ feature mapì˜ í¬ê¸° 14x14ì— ë§ê²Œ ì ˆëŒ€ì¢Œí‘œë¡œ ë³€í™˜í•´ì„œ feature map ë‚´ì—ì„œ region proposalì´ encodeí•˜ëŠ” ì˜ì—­ì„ ì°¾ëŠ” ê²ƒì´ë‹¤.

ì´ì–´ì„œ RoI Projectionì„ í•˜ëŠ” ì½”ë“œë¥¼ ì´ì–´ ë¶™ì—¬ë³´ì.


```python
import torch
import torch.nn as nn
import numpy as np

class RoIPool(nn.Module):
  def __init__(self, output_size):
    super().__init__()
    self.maxpool = nn.AdaptiveMaxPool2d(output_size)
    self.size = output_size
  
  def forward(self, images, rois, roi_idx):
    n = rois.shape[0]  # RoIì˜ ê°œìˆ˜

    h = images.size(2)  
    w = images.size(3)  

    x1 = rois[:,0]
    y1 = rois[:,1]
    x2 = rois[:,2]
    y2 = rois[:,3]

    x1 = np.floor(x1 * w).astype(int)
    x2 = np.ceil(x2 * w).astype(int)
    y1 = np.floor(y1 * h).astype(int)
    y2 = np.ceil(y1 * h).astype(int)

    # RoI Projection ìˆ˜í–‰ 
    res = []

    # RoI ìˆ˜ë§Œí¼ ìˆœíšŒ
    for i in range(n):  
      img = images[roi_idx[i]].unsqueeze(0) # ië²ˆì§¸ roi_idxì— í•´ë‹¹í•˜ëŠ” feature map
      img = img[:, :, y1[i]:y2[i], x1[i]:x2[i]] # ì˜ë¼ë‚´ê¸°
      img = self.maxpool(img) # Adaptive Max Pooling ì ìš©
      res.append(img)
    res = torch.cat(res,dim=0)
    return res # 7x7 í¬ê¸°ì˜ feature mapì´ RoI ìˆ˜ë§Œí¼ ì €ì¥ëœ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
```

Max Poolingì„ ì‚¬ìš©í•  ë•Œ ì…ë ¥ feature map í¬ê¸°ì™€ ì¶œë ¥ feature mapì˜ í¬ê¸°ë¥¼ ê³ ë ¤í•´ì„œ strideì™€ kernelì˜ í¬ê¸°ë¥¼ ì¡°ì •í•˜ëŠ” Adaptive Max Poolingì„ ì‚¬ìš©í•œë‹¤. RoI Projectionì„ ê±°ì³ì„œ ìµœì¢…ì ìœ¼ë¡œ 7x7 í¬ê¸°ì˜ feature mapì´ RoI ìˆ˜ë§Œí¼ ì €ì¥ëœ ë¦¬ìŠ¤íŠ¸ê°€ ë°˜í™˜ëœë‹¤.

### 2. Initializing pre-trained CNN
ë‹¤ìŒìœ¼ë¡œ ì‚¬ì „ í›ˆë ¨ëœ VGG16 ëª¨ë¸ì„ load í•œ í›„ detection taskì— ë§ê²Œ CNNì„ ìˆ˜ì •í•˜ëŠ” ì½”ë“œë¥¼ ë¶„ì„í•´ë³´ì.


```python
from torch.autograd.variable import Variable
import torchvision

class RCNN(nn.Module):
  def __init__(self):
    super().__init__()

    rawnet = torchvision.models.vgg16_bn(pretrained=True) # ì‚¬ì „ í›ˆë ¨ëœ VGG16_bn ëª¨ë¸ ë¡œë“œ
    self.seq = nn.Sequential(*list(rawnet.features.children())[:-1]) # ë§ˆì§€ë§‰ max pooling ì œê±°
    self.roipool = RoIPool(output_size=(7,7)) # ë§ˆì§€ë§‰ pooling layerë¥¼ RoI Pooling layerë¡œ ëŒ€ì²´
    self.feature = nn.Sequential(*list(rawnet.classifier.children())[:-1]) # ë§ˆì§€ë§‰ fc layer ì œê±°

    _x = Variable(torch.Tensor(1,3,224,224)) # VGG16ì— ì…ë ¥ë˜ëŠ” ë°ì´í„°ì˜ í¬ê¸°(224x244 RGB) ì •ì˜
    _r = np.array([[0., 0., 1., 1.]])
    _ri = np.array([0])

    # ì›ë³¸ ì´ë¯¸ì§€ë¥¼ conv layer, roi pooling layer, fc layerì— ìˆœì°¨ì ìœ¼ë¡œ ì…ë ¥í•´ì„œ ê³ ì •ëœ í¬ê¸° (7x7)ì˜ feature vector ì–»ëŠ”ë‹¤.
    _x = self.feature(self.roipool(self.seq(_x),_r,_ri).view(1,-1)) 

    feature_dim = _x.size(1)
    self.cls_score = nn.Linear(feature_dim, N_CLASS + 1) # feature vectorë¥¼ Classifierì— ì£¼ì…
    self.bbox = nn.Linear(feature_dim, 4*(N_CLASS+1)) # feature vectorë¥¼ BBRì— ì£¼ì…
    
    self.cel = nn.CrossEntropyLoss() # ë¶„ë¥˜ ì†ì‹¤í•¨ìˆ˜ ì •ì˜
    self.sl1 = nn.SmoothL1Loss()  # BBR ì†ì‹¤í•¨ìˆ˜ ì •ì˜

  def forward(self, inp, rois, ridx):
    res = inp # ì…ë ¥ ì´ë¯¸ì§€ ë°ì´í„°
    res = self.seq(res) # pooling ì´ì „ê¹Œì§€ì˜ ê³¼ì •
    res = self.roipool(res,rois,ridx) # RoI Pooling 
    res = res.detach() # ì—°ì‚° x
    res = res.view(res.size(0), -1) # fc layerì— ì£¼ì…í•˜ê¸° ìœ„í•´ í¼ì¹˜ê¸°
    feat = self.feature(res) # fc layerì—ì„œ feature ì¶”ì¶œ

    cls_score = self.cls_score(feat) # ë¶„ë¥˜ ì ìˆ˜
    bbox = self.bbox(feat).view(-1, N_CLASS+1, 4) # BBR ê²°ê³¼

    return cls_score, bbox
```

### 3. Multi-taks Loss
ìœ„ì˜ ì½”ë“œì— ì´ì–´ì„œ Multi-task Lossë¥¼ êµ¬í˜„í•œ ë¶€ë¶„ì„ ë¶„ì„í•´ë³´ì.


```python
from torch.autograd.variable import Variable
import torchvision

class RCNN(nn.Module):
  def __init__(self):
    super().__init__()

    rawnet = torchvision.models.vgg16_bn(pretrained=True)
    self.seq = nn.Sequential(*list(rawnet.features.children())[:-1]) 
    self.roipool = RoIPool(output_size=(7,7)) 
    self.feature = nn.Sequential(*list(rawnet.classifier.children())[:-1]) 

    _x = Variable(torch.Tensor(1,3,224,224)) 
    _r = np.array([[0., 0., 1., 1.]])
    _ri = np.array([0])
    _x = self.feature(self.roipool(self.seq(_x),_r,_ri).view(1,-1)) 

    feature_dim = _x.size(1)
    self.cls_score = nn.Linear(feature_dim, N_CLASS + 1) 
    self.bbox = nn.Linear(feature_dim, 4*(N_CLASS+1)) 

    self.cel = nn.CrossEntropyLoss()
    self.sl1 = nn.SmoothL1Loss()  

  def forward(self, inp, rois, ridx):
    res = inp 
    res = self.seq(res) 
    res = self.roipool(res,rois,ridx) 
    res = res.detach() 
    res = res.view(res.size(0), -1) 
    feat = self.feature(res) 

    cls_score = self.cls_score(feat)
    bbox = self.bbox(feat).view(-1, N_CLASS+1, 4) 

    return cls_score, bbox

  def calc_loss(self, probs, bbox, labels, gt_bbox):  # Multi task Loss êµ¬í˜„
    loss_sc = self.cel(probs, labels) # í¬ë¡œìŠ¤ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ë¡œ Classifier ì†ì‹¤ êµ¬í˜„

    lbl = labels.view(-1,1,1).expand(labels.size(0),1,4)
    mask = (labels != 0).float().view(-1,1).expand(labels.size(0),4)
    loss_loc = self.sl1(bbox.gather(1,lbl).squeeze(1) * mask, gt_bbox * mask)

    lmb = 1.0
    loss = loss_sc + lmb * loss_loc

    return loss, loss_sc, loss_loc
```

Classifierì˜ lossëŠ” Crossentropy lossë¥¼ í†µí•´ì„œ êµ¬í•˜ë©´ ë˜ì§€ë§Œ, BBRì˜ lossëŠ” êµ¬í•˜ê¸° ì‚´ì§ ë³µì¡í•˜ë‹¤. Multi-task lossë¥¼ ë‹¤ì‹œ í•œë²ˆ ë³´ì.

![pyfrcnn2](https://user-images.githubusercontent.com/77332628/211156320-ce1a88c1-0ba0-47ad-b949-abfb23c1dbba.png)

BBRì˜ lossì—ëŠ” í•™ìŠµ ë°ì´í„°ê°€ positive/negative sample ì—¬ë¶€ë¥¼ ì•Œë ¤ì£¼ëŠ” index parameter $u$ê°€ ê³±í•´ì ¸ ìˆë‹¤. $u$ëŠ” ìœ„ì˜ ì½”ë“œì—ì„œ mask ë³€ìˆ˜ë¡œ êµ¬í˜„ë˜ì–´ ìˆë‹¤. mask ë³€ìˆ˜ëŠ” labelsì— ì €ì¥ëœ ë°°ì—´ì„ bounding boxì— ëŒ€í•œ ì •ë³´ê°€ ì €ì¥ëœ ë°°ì—´ì˜ í¬ê¸°ì— ë§ê²Œ ë³€í™˜í•œ ë°°ì—´ì´ë‹¤. maskë¥¼ ì˜ˆì¸¡ bounding boxì— í•´ë‹¹í•˜ëŠ” bbox ë³€ìˆ˜ì™€, ground truth boxì— í•´ë‹¹í•˜ëŠ” gt_bbox ë³€ìˆ˜ì— ê³±í•´ì¤€ í›„ Smooth L1 lossë¥¼ êµ¬í•œë‹¤. ê·¸ë¦¬ê³  ìµœì¢…ì ìœ¼ë¡œ ë‘ loss ì‚¬ì´ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ëŠ” lambdaì— í•´ë‹¹í•˜ëŠ” lmb ë³€ìˆ˜ë¥¼ 1ë¡œ ì„¤ì •í•˜ê³  ë‘ lossë¥¼ ë”í•´ì„œ ìµœì¢…ì ìœ¼ë¡œ multi-task lossë¥¼ ë°˜í™˜í•œë‹¤.


ì°¸ê³ í•œ ë¸”ë¡œê·¸ì˜ ê¸€ì“´ì´ëŠ” ì´ ë¶€ë¶„ì„ ë¶„ì„í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì–´ë ¤ì› ë‹¤ê³  í•œë‹¤. 

### 4. Fast R-CNN í›ˆë ¨í•˜ê¸°
ë‹¤ìŒìœ¼ë¡œëŠ” batchë³„ë¡œ Fast RCNNì´ í•™ìŠµí•˜ëŠ” ê³¼ì •ì„ êµ¬í˜„í•œ ì½”ë“œë¥¼ ì‚´í´ë³´ì. ì›ë³¸ ì´ë¯¸ì§€ì™€ RoIë¥¼ ìœ„ì—ì„œ ì •ì˜í•œ R-CNNì— ì£¼ì…í•˜ê³ , lossë¥¼ êµ¬í•˜ëŠ” ê³¼ì •ì´ êµ¬í˜„ë˜ì–´ ìˆë‹¤.


```python
def train_batch(img, rois, ridx, gt_cls, gt_tbbox, is_val = False):
  sc, r_bbox = RCNN(img, rois, ridx) # class score, bboxë¥¼ êµ¬í•œë‹¤.
  loss, loss_sc, loss_loc = RCNN.calc_loss(sc, r_bbox, gt_cls, gt_tbbox) # loss ê³„ì‚°
  fl = loss.data.cpu().numpy()[0]
  fl_sc = loss_sc.data.cpu().numpy()[0]
  fl_loc = loss_loc.data.cpu().numpy()[0]

  if not is_val: # ê²€ì¦ ê³¼ì •ì´ ì•„ë‹ ê²½ìš°
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
```

ë‹¤ìŒìœ¼ë¡œëŠ” epoch ë³„ë¡œ í•™ìŠµì‹œí‚¤ëŠ” ê³¼ì •ì—ì„œ Hierarchical samplingì„ í†µí•´ ì ì ˆí•œ í•™ìŠµ ë°ì´í„°ë¥¼ samplingí•˜ëŠ” ê³¼ì •ì„ êµ¬í˜„í•œë‹¤. Hierarchical samplingì€ ê°„ë‹¨íˆ ë§í•´ì„œ featuring sharingì„ ê°€ëŠ¥í•˜ê²Œ í•´ì„œ ì—°ì‚°ì„ ê³µìœ í•  ìˆ˜ ì—†ëŠ” RCNNì˜ ë‹¨ì ì„ í•´ê²°í•˜ëŠ” ê¸°ë²•ì´ë‹¤. 

ì›ë³¸ ì´ë¯¸ì§€ ì¤‘ 2ì¥ì„ sampling í•œ í›„, ê° ì´ë¯¸ì§€ì—ì„œ 64ì¥ì˜ RoIë¥¼ samplingí•œë‹¤. ì´ì²˜ëŸ¼ ê°™ì€ ì´ë¯¸ì§€ì—ì„œ samplingí•œ RoIëŠ” forward, back propagationì‹œ, **ì—°ì‚°ê³¼ ë©”ëª¨ë¦¬ë¥¼ ê³µìœ í•  ìˆ˜ ìˆë‹¤.** ì „ì²´ RoI ì¤‘ì—ì„œ positive sampleì€ 25%, ë‚˜ë¨¸ì§€ëŠ” negative sampleë¡œ êµ¬ì„±í•œë‹¤.


```python
from tqdm import trange

def train_epoch(run_set, is_val=False):
  I = 2 # number of image
  B = 64 # number of RoIs per image
  POS = int(B*0.25) # positive sample ë¹„ìœ¨ 25%
  NEG = B - POS

  # shuffle images
  Nimg = len(run_set)
  perm = np.random.permutation(Nimg)
  perm = run_set[perm]  

  losses = []
  losses_sc = []
  losses_loc = []

  # ì „ì²´ ì´ë¯¸ì§€ë¥¼ I(=2)ê°œì”©ë§Œí¼ ì²˜ë¦¬
  for i in trange(0, Nimg , I):
    lb = i 
    rb = min(i+I, Nimg)
    torch_seg = torch.from_numpy(perm[lb:rb]) # read 2 images
    img = Variable(train_imgs[torch_seg], volatile=is_val)
    ridx = []
    glo_ids = []
```

ì´ì–´ì„œ positive/negative sampleì˜ indexê°€ ì €ì¥ëœ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì§€ì •í•œ positive/negative ìˆ˜ì— ë§ê²Œ sampling í•œë‹¤. ê·¸ë¦¬ê³  ì´ë¯¸ì§€ 2ì¥ì—ì„œ sampling í•œ RoIë¥¼ glo_ids ë³€ìˆ˜ì— ì €ì¥í•´ì„œ epochë‹¹ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©í•œë‹¤.


```python
def train_epoch(run_set, is_val=False):
  I = 2 
  B = 64 
  POS = int(B*0.25) 
  NEG = B - POS

  Nimg = len(run_set)
  perm = np.random.permutation(Nimg)
  perm = run_set[perm]  

  losses = []
  losses_sc = []
  losses_loc = []

  for i in trange(0, Nimg , I):
    lb = i 
    rb = min(i+I, Nimg)
    torch_seg = torch.from_numpy(perm[lb:rb]) 
    img = Variable(train_imgs[torch_seg], volatile=is_val)
    ridx = []
    glo_ids = []

    # ì´ì–´ì„œ
    for j in range(lb,rb):
      info = train_img_info[perm[j]]

      # RoIì˜ positive, negative idxì— ëŒ€í•œ ë¦¬ìŠ¤íŠ¸
      pos_idx = info['pos_idx']
      neg_idx = info['neg_idx']
      ids = []

      ì§€ì •í•œ positive/negative ìˆ˜ì— ë§ê²Œ sampling
      if len(pos_idx) > 0:
                ids.append(np.random.choice(pos_idx, size=POS))
      if len(neg_idx) > 0:
                ids.append(np.random.choice(neg_idx, size=NEG))
      if len(ids) == 0:
          continue
      ids = np.concatenate(ids, axis=0)

      # glo_ids : ë‘ ì´ë¯¸ì§€ì— ëŒ€í•œ positive, negative sampleì˜ idxë¥¼ ì €ì¥í•œ ë¦¬ìŠ¤íŠ¸
      glo_dis.append(ids)
      ridx += [j-lb] * ids.shape[0]

      if len(ridx) == 0 :
        continue
      glo_ids = np.concatenate(glo_ids, axis=0)
      ridx = np.array(ridx)

      # Hierarchical samplingì„ í†µí•´ êµ¬ì„±í•œ í•™ìŠµ ë°ì´í„°ë¥¼ Fast RCNNì— ì£¼ì…í•´ì„œ lossë¥¼ êµ¬í•œë‹¤.
      rois = train_roi[glo_ids]
      gt_cls = Variable(torch.from_numpy(train_cls[glo_ids]), volatile=is_val).cuda()
      gt_tbbox = Variable(torch.from_numpy(train_tbbox[glo_ids]), volatile=is_val).cuda()

      loss, loss_sc, loss_loc = train_batch(img, rois, ridx, gt_cls, gt_tbbox, is_val=is_val)
      losses.append(loss)
      losses_sc.append(loss_sc)
      losses_loc.append(loss_loc)

  avg_loss = np.mean(losses)
  avg_loss_sc = np.mean(losses_sc)
  avg_loss_loc = np.mean(losses_loc)
  print(f'Avg loss = {avg_loss:.4f}; loss_sc = {avg_loss_sc:.4f}, loss_loc = {avg_loss_loc:.4f}')
    
  return losses, losses_sc, losses_loc
```

is_valì„ Falseë¡œ ì„¤ì •í•´ì„œ í›ˆë ¨ ê³¼ì •ì—ì„œ ë‚˜ì˜¨ ê°’ë“¤ì„ ë°˜í™˜í•˜ê³ , is_valì„ Trueë¡œ ì„¤ì •í•´ì„œ ê²€ì¦ ê³¼ì •ì„ ê±°ì¹œë‹¤.


```python
def start_training(n_epoch=2):
    tl = []
    ts = []
    to = []
    vl = []
    vs = [] 
    vo = []
    for i in range(n_epoch):
        print(f'===========================================')
        print(f'[Training Epoch {i+1}]')
        train_loss, train_sc, train_loc = train_epoch(train_set, False)
        print(f'[Validation Epoch {i+1}]')
        val_loss, val_sc, val_loc = train_epoch(val_set, True)
        
        tl.append(train_loss)
        ts.append(train_sc)
        to.append(train_loc)
        vl.append(val_loss)
        vs.append(val_sc)
        vo.append(val_loc)
        
    plot('loss','Train/Val : Loss', 'Train', 'Validation', tl, vl, n_epoch)
    plot('loss_sc','Train/Val : Loss_sc', 'Train', 'Validation', ts, vs, n_epoch)
    plot('loss_loc','Train/Val : Loss_loc', 'Train', 'Validation', to, vo, n_epoch)
```

ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ê³¼ì •ê³¼ ê²€ì¦ ì…‹ ë°ì´í„°ë¥¼ ì •ì˜í•˜ëŠ” ê³¼ì •ê³¼ í…ŒìŠ¤íŠ¸ ì…‹ì„ ëŒë¦¬ëŠ” ê³¼ì • ë“± ì½”ë“œì˜ ëª¨ë“  ê³¼ì •ì„ ë‹¤ë£¨ì§€ëŠ” ëª»í–ˆì§€ë§Œ ì´ë ‡ê²Œ í•´ì„œ Fast RCNN ëª¨ë¸ì„ íŒŒì´í† ì¹˜ë¡œ í•œë²ˆ êµ¬í˜„í•´ë´¤ë‹¤. 

ì°¸ê³   : https://github.com/gary1346aa/Fast-RCNN-Object-Detection-Pytorch,

https://stackoverflow.com/questions/53841509/how-does-adaptive-pooling-in-pytorch-work,

https://herbwood.tistory.com/9?category=867198
