---
title : '[CV/Pytorch] íŒŒì´í† ì¹˜ë¡œ YOLO v1 êµ¬í˜„í•˜ê¸° ğŸ¤Ÿ'
layout: single
toc: true
toc_sticky: true
categories:
  - pytorchOD
---

## Pytorchë¡œ YOLO v1 êµ¬í˜„í•˜ê¸°

ì´ë²ˆ ê¸€ì—ì„œëŠ” pytorchë¥¼ ì‚¬ìš©í•´ì„œ YOLO v1ì„ êµ¬í˜„í•´ë³¼ê±´ë°, [aladdinperssonë‹˜ì˜ github repository](https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/object_detection/YOLO)ì— ì˜¬ë¼ì˜¨ ì½”ë“œë¥¼ ë¦¬ë·°í•´ ë³¼ ê²ƒì´ë‹¤. YOLO v1 ëª¨ë¸ì— ëŒ€í•œ ì„¤ëª…ì€ ì´ì „ ê¸€([**ë§í¬**](https://hamin-chang.github.io/cv-objectdetection/yolov1/))ë¥¼ ì°¸ê³ í•˜ë©´ ë˜ê² ë‹¤. 

### 1. DarkNet êµ¬í˜„í•˜ê¸°

![111](https://user-images.githubusercontent.com/77332628/214053977-e412dbe6-b054-40c5-82d5-02c9d7e9595c.png)

DarkNetì€ ìœ„ ì´ë¯¸ì§€ì²˜ëŸ¼ networkì˜ ìµœì¢… feature mapì˜ í¬ê¸°ê°€ 7x7x30ì´ ë˜ë„ë¡ ì„¤ê³„í•˜ë©´ ë˜ëŠ”ë°, ì½”ë“œê°€ í¥ë¯¸ë¡œìš´ ì ì€ networkì˜ ê° conv layerì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ê°’ì„ config ë³€ìˆ˜ì— ì €ì¥í•œ í›„ ì´ë¥¼ ë¶ˆëŸ¬ì™€ ì‚¬ìš©í•œë‹¤ëŠ” ê²ƒì´ë‹¤.

architecture_config ë¦¬ìŠ¤íŠ¸ì˜ ê° ìš”ì†ŒëŠ” conv layerì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì¸ (kernel_size, num_filters, stride, padding)ì´ íŠœí”Œ í˜•ì‹ìœ¼ë¡œ ì €ì¥ë˜ì–´ ìˆê³ , ì¤‘ê°„ì˜ 'M' ë¬¸ìì—´ì€ max poolingì„ ì˜ë¯¸í•œë‹¤. ë˜í•œ ë¦¬ìŠ¤íŠ¸ ìš”ì†ŒëŠ” ë§ˆì§€ë§‰ ì •ìˆ˜ê°’ë§Œí¼ layerë¥¼ ë°˜ë³µí•œë‹¤.



```python
architecture_config = [
    (7, 64, 2, 3),
    "M",
    (3, 192, 1, 1),
    "M",
    (1, 128, 1, 0),
    (3, 256, 1, 1),
    (1, 256, 1, 0),
    (3, 512, 1, 1),
    "M",
    [(1, 256, 1, 0), (3, 512, 1, 1), 4],
    (1, 512, 1, 0),
    (3, 1024, 1, 1),
    "M",
    [(1, 512, 1, 0), (3, 1024, 1, 1), 2],
    (3, 1024, 1, 1),
    (3, 1024, 2, 1),
    (3, 1024, 1, 1),
    (3, 1024, 1, 1),
]
```

ê·¸ë¦¬ê³  ë‚˜ì„œ architecture_config ë¦¬ìŠ¤íŠ¸ ìš”ì†Œì˜ typeì— ë”°ë¼ì„œ ì¡°ê±´ë¬¸ìœ¼ë¡œ ì„œë¡œ ë‹¤ë¥¸ layerë¥¼ ì¶”ê°€í•¨ìœ¼ë¡œì¨ ëª¨ë¸ì„ ì„¤ê³„í•œë‹¤. ë§Œì•½ ë¦¬ìŠ¤íŠ¸ ìš”ì†Œê°€ íŠœí”Œì´ë©´ í•´ë‹¹ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì— ë§ëŠ” conv layerë¥¼, ë¬¸ìì—´ì´ë©´ max poolingì„, ë¦¬ìŠ¤íŠ¸ë©´ ë§ˆì§€ë§‰ ì •ìˆ˜ê°’ë§Œí¼ layerë¥¼ ë°˜ë³µí•´ì„œ ì „ì²´ì ì¸ DarkNet ëª¨ë¸ì„ êµ¬ì„±í•œë‹¤.


```python
import torch
import torch.nn as nn

class CNNBlock(nn.Module):
  def __init__(self, in_channels, out_channels, **kwargs):
    super(CNNBlock, self).__init__()
    self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)
    self.batchnorm = nn.BatchNorm2d(out_channels)
    self.leakyrelu = nn.LeakyReLU(0.1)

  def forward(self,x):
    return self.leakyrelu(self.batchnorm(self.conv(x)))
  
class Yolov1(nn.Module):
  def __init__(self, in_channels=3, **kwargs):
    super(Yolov1, self).__init__()
    self.architecture = architecture_config
    self.in_channels = in_channels
    self.darknet = self._create_conv_layers(self.architecture)
    self.fcs = self._create_fcs(**kwargs)
  
  def forward(self,x):
    x = self.darknet(x)
    return self.fcs(torch.flatten(x, start_dim=1))

  def _create_conv_layers(self, architecture):
    layers = []
    in_channels = self.in_channels

    for x in architecture:
      if type(x) == tuple:
        layers += [CNNBlock(in_channels, x[1], kernel_size = x[0], strid = x[2], padding = x[3])]
        in_channels = x[1]

      elif type(x) == str:
        layers += [nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))]

      elif type(x) == list:
        conv1 = x[0]
        conv2 = x[1]
        num_repeats = x[2]

        for _ in range(num_repeats):
          layers += [CNNBlock(in_channels, conv1[1], kernel_size = conv1[0], stride = conv1[2], padding = conv1[3])]
          layers += [CNNBlock(conv1[1], conv2[1], kernel_size = conv2[0], stride = conv2[2], padding = conv2[3])]
          in_channels = conv2[1]

    return nn.Sequential(*layers)

  def _create_fcs(self, split_size, num_boxes, num_classes):
    S, B, C = split_size, num_boxes, num_classes

    return nn.Sequential(
        nn.Flatten(),
        nn.Linear(1024 * S * S, 496),
        nn.Dropout(0.0),
        nn.LeakyReLU(0.1),
        nn.Linear(496, S*S*(C+B*5))
    )

```

### 2. YOLO v1 ì†ì‹¤í•¨ìˆ˜ êµ¬í˜„

![222](https://user-images.githubusercontent.com/77332628/214053979-398764af-147d-4f14-9738-ec1c323dceec.png)

ì´ë²ˆ ì½”ë“œ ë¦¬ë·°ì—ì„œ ì¤‘ì ì ìœ¼ë¡œ ì‚´í´ë´ì•¼í•  ë¶€ë¶„ì´ë‹¤. êµ¬í˜„í•˜ëŠ” ë¶€ë¶„ì—ì„œ ìµœì¢… feature mapì— ëŒ€í•´ì„œ ì²˜ë¦¬í•´ì¤˜ì•¼ í•  ê³¼ì •ë“¤ì´ ëª‡ê°€ì§€ ìˆë‹¤.

ìš°ì„  YoloLoss í´ë˜ìŠ¤ë¡œ ì •ì˜í•´ì„œ gridì˜ í¬ê¸° S, grid cell ë³„ ì˜ˆì¸¡ bounding boxì˜ ìˆ˜ë¥¼ B, ì˜ˆì¸¡í•˜ëŠ” classì˜ ìˆ˜ Cë¥¼ ìƒì„±ìë¡œ ë°›ê³  ê°€ì¤‘ì¹˜ íŒŒë¼ë¯¸í„°ì¸ $Î»_{coord}$, $Î»_{noobj}$ë„ ì •ì˜í•´ì¤€ë‹¤.


```python
from utils import intersection_over_union

class YoloLoss(nn.Module):
  def __init__(self, S=7, B=2, C=20):
    super(YoloLoss,self).__init__()
    self.mse = nn.MSELoss(reduction='sum')
    self.S = S
    self.B = B
    self.C = C

    self.lambda_coord = 5
    self.lambda_noobj = 0.5

    # ì´ì–´ì„œ 
```

ê·¸ë¦¬ê³  forward pass ì‹œ ì²˜ë¦¬í•  ê³¼ì •ì„ ì •ì˜í•œë‹¤. ê° grid cellë§ˆë‹¤ 2ê°œì˜ bounding boxë¥¼ ì˜ˆì¸¡í•˜ê³  ê·¸ ì¤‘ confidence scoreê°€ ë†’ì€ 1ê°œì˜ bounding boxë¥¼ í•™ìŠµì— ì‚¬ìš©í•˜ëŠ” ê³¼ì •ì„ êµ¬í˜„í•œë‹¤. 



```python
  # ì´ì–´ì„œ
  def forward(self, predictions,target):
    # DarkNetì´ ìµœì¢…ì ìœ¼ë¡œ ì¶œë ¥í•˜ëŠ” 7x7x30 í¬ê¸°ì˜ feature mapì„ flattení•œ ê²°ê³¼ [c1, c2, ..., c20, p_c1, x, y, w, h, p_c2, x, y, w, h]
    predictions = predictions.reshape(-1, self.S, self.S, self.C + self.B * 5)

    # ì •ë‹µê°’ì¸ target ì¢Œí‘œì™€ ë¹„êµí•´ì„œ IoU ê³„ì‚°
    iou_b1 = intersection_over_union(predictions[..., 21:25], target[..., 21:25]) # predictions[...,21:25] => ì²« ë²ˆì§¸ bounding boxì˜ ì¢Œí‘œê°’
    iou_b2 = intersection_over_union(predictions[..., 26:30], target[..., 21:25]) # predictions[...,26:30] => ë‘ ë²ˆì§¸ bounding boxì˜ ì¢Œí‘œê°’
    
    ious = torch.cat([iou_b1.unsqueeze(0), iou_b2.unsqueeze(0)], dim=0)

    iou_maxes, bestbox = torch.max(ious, dim=0
                                   )
    # target[...,20]ë¥¼ í†µí•´ì„œ í•´ë‹¹ grid cellì— ground truth boxì˜ ì¤‘ì‹¬ì´ ì¡´ì¬í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ í™•ì¸
    # ì•½ ì¡´ì¬í•œë‹¤ë©´ exist_box = 1, ì•„ë‹ˆë©´ exist_box = 0
    exists_box = target[...,20].unsqueeze(3)

    # ì´ì–´ì„œ

```

ì´ì œ ë¨¼ì € **Localization Loss**ë¥¼ êµ¬í˜„í•´ë³´ì. best_box ë³€ìˆ˜ë¥¼ í™œìš©í•´ì„œ ì‹¤ì œ bounding box ì˜ˆì¸¡ ì¤‘ IoU ê°’ì´ ë” í° boxë¥¼ ìµœì¢… ì˜ˆì¸¡ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. ê·¸ë¦¬ê³  width, height ê°’ì—ëŠ” ë£¨íŠ¸ë¥¼ ì”Œì›Œì£¼ê³  ê·¸ ë‹¤ìŒ bounding box ì¢Œí‘œê°’ì— ëŒ€í•˜ì—¬ mseë¥¼ ê³„ì‚°í•´ì¤€ë‹¤.


```python
    # ì´ì–´ì„œ
    box_predictions = exists_box * ((bestbox * predictions[..., 26:30] + (1-bestbox) * predictions[..., 21:25]))
    box_targets = exists_box * target[..., 21:25]

    box_predictions[..., 2:4] = torch.sign(box_predictions[..., 2:4]) * torch.sqrt(torch.abs(box_predictions[..., 2:4] + 1e-6))
    box_targets[..., 2:4] = torch.sqrt(box_targets[..., 2:4])
    box_loss = self.mse(torch.flatten(box_predictions, end_dim = -2),
                        torch.flatten(box_targets, end_dim = -2))
    
    # ì´ì–´ì„œ
    
```

ë‹¤ìŒìœ¼ë¡œ Confidence lossë¥¼ êµ¬í˜„í• ê±´ë°, ë¨¼ì € objectê°€ ì‹¤ì œë¡œ ì¡´ì¬í•  ê²½ìš°ì˜ confidence lossë¶€í„° êµ¬í•œë‹¤. predictions[...,25:26]ì€ ì²« ë²ˆì§¸ boxì˜ confidence scoreë¥¼, prediction[..., 20:21]ì€ ë‘ ë²ˆì§¸ boxì˜ confidence scoreë¥¼ ì˜ë¯¸í•œë‹¤. exists_box ë³€ìˆ˜ë¥¼ í†µí•´ grid cellì— í• ë‹¹ëœ ground truth boxì˜ ì¤‘ì‹¬ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ lossë¥¼ êµ¬í•œë‹¤.


```python
    # ì´ì–´ì„œ

    # ê°€ì¥ ë†’ì€ IoUë¥¼ ê°€ì§„ bboxì— ëŒ€í•œ confidence score
    pred_box = (bestbox * predictions[...,25:26] + (1-bestbox) * predictions[...,20:21])

    object_loss = self.mse(torch.flatten(exists_box * pred_box),
                           torch.flatten(exists_box * target[..., 20:21]))
    
    # ì´ì–´ì„œ
```

ë‹¤ìŒìœ¼ë¡œëŠ” objectê°€ ì—†ì„ ê²½ìš°ì˜ confidence lossë¥¼ êµ¬í˜„í•˜ëŠ” ê³¼ì •ì„ ì‚´í´ë³´ì. ì´ ê²½ìš° ë‘ bounding boxë¥¼ ëª¨ë‘ í•™ìŠµì— ì°¸ì—¬ì‹œí‚¨ë‹¤. 


```python
    # ì´ì–´ì„œ

    no_object_loss = self.mse(torch.flatten((1-exists_box) * predictions[..., 20:21], start_dim = 1),
                              torch.flatten((1-exists_box) * target[..., 20:21], start_dim = 1))
    
    no_object_loss += self.mse(torch.flatten((1 - exists_box) * predictions[..., 25:26], start_dim=1),
                               torch.flatten((1 - exists_box) * target[..., 20:21], start_dim=1))

    # ì´ì–´ì„œ
```

ë§ˆì§€ë§‰ìœ¼ë¡œ Class lossë¥¼ êµ¬í•œë‹¤. predictions[..., :20]ì— í•´ë‹¹í•˜ëŠ”, ì¦‰ 20ê°œì˜ classì˜ scoreë¥¼ targetê³¼ ë¹„êµí•´ì„œ mse lossë¥¼ êµ¬í•˜ê³  ì´í›„ YoloLossì˜ ìƒì„±ìì—ì„œ ì •ì˜í•œ ê°€ì¤‘ì¹˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°ê° ê³±í•´ì£¼ê³  localization, confidence, class lossë¥¼ ëª¨ë‘ ë”í•´ì„œ ìµœì¢… lossë¥¼ êµ¬í•œë‹¤.


```python
    # ì´ì–´ì„œ

    class_loss = self.mse(torch.flatten(exists_box * predictions[..., :20], end_dim= -2),
                          torch.flatten(exists_box * target[..., 20], end_dim= -2))
    
    loss = (self.lambda_coord * box_loss 
            + object_loss 
            + self.lambda_noobj * no_object_loss
            + class_loss)
    
    return loss
```

### 3. Custom Dataset

ë§ˆì§€ë§‰ìœ¼ë¡œëŠ” Datasetì„ ì •ì˜í•˜ëŠ” ë¶€ë¶„ì´ë‹¤. ì´ ë¶€ë¶„ì—ì„œ ì´ë¯¸ì§€ì˜ ê° grid cellì— ground truth boxì˜ ì¤‘ì‹¬ì´ ìˆëŠ”ì§€ ì§€ì •í•´ì¤€ë‹¤.


```python
import torch
import os
import pandas as pd
from PIL import Image

class VOCDataset(torch.utils.data.Dataset):
  def __init__(self, csv_file, img_dir, label_dir, S=7, B=2, C=20, transform=None):
    self.annotations = pd.read_csv(csv_file)
    self.img_dir = img_dir
    self.label_dir = label_dir
    self.transform = transform
    self.S = S 
    self.B = B
    self.C = C

  def __len__(self):
    return len(self.annotations)

  def __getitem__(self, index):
    label_path = os.path.join(self.label_dir, self.annotations.iloc[index,1])
    boxes = []
    with open(label_path) as f:
      for label in f.readlines():
        class_label,x,y,width,height = [float(x) if float(x) != int(float(x)) else int(x)
                                        for x in label.replace("\n","").split()]
        boxes.append([class_label, x, y, width, height])

      img_path = os.path.join(self.img_dir, self.annotations.iloc[index,0])
      image = Image.open(img_path)
      boxes = torch.tensor(boxes)

      if self.transform:
          image, boxes = self.transform(image, boxes)
        
      label_matrix = torch.zeros((self.S, self.S, self.C + 5 * self.B)) # grid cellê³¼ ê°™ì€ 7x7x30 ë°°ì—´
      for box in boxes :
        # boxes ë³€ìˆ˜ì— ì „ì²´ ground truth boxì˜ [x,y,w,h]ê°€ ì €ì¥ ë˜ì–´ìˆì–´ì„œ
        class_label, x, y, width, height = box.tolist()
        class_label = int(class_label)

        i, j = int(self.S * y), int(self.S * x) # i,jëŠ” cellì˜ í–‰ê³¼ ì—´ 

        # ê°ê°ì˜ ground truth boxë¥¼ ìˆœíšŒí•˜ë©´ì„œ ground truth boxì˜ ì¤‘ì‹¬ ì¢Œí‘œë¥¼ ê³„ì‚°í•˜ê³ ,
        x_cell, y_cell = self.S * x - j, self.S * y - i
        width_cell, height_cell = (width * self.S , height * self.S)

        # label_matrixì— confidence scoreì™€ bounding box ì¢Œí‘œ ì €ì¥í•˜ëŠ”ë°,
        # ground truth boxì˜ ì¤‘ì‹¬ì´ íŠ¹ì • cellì— ì¡´ì¬í•˜ë©´ í•´ë‹¹ cellì˜ 20ë²ˆì§¸ index(confidence score) = 1 ì§€ì •
        if label_matrix[i, j, 20] == 0:
          label_matrix[i, j, 20] = 1

          # bbox ì¢Œí‘œ
          box_coordinates = torch.tensor(
              [x_cell, y_cell, width_cell, height_cell])
          label_matrix[i, j, 21:25] = box_coordinates

          # class_labelì—ëŠ” one hot encoding ì„¤ì •
          label_matrix[i, j, class_label] = 1
      
      return image, label_matrix
```

ì§€ê¸ˆê¹Œì§€ëŠ” YOLO v1ì„ êµ¬í˜„í•˜ê¸° ìœ„í•´ì„œ ëª¨ë¸ì„ ì„¤ê³„í•˜ê³  ì†ì‹¤í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ê³  PASCAL VOC ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê¸° ìœ„í•œ ì½”ë“œë¥¼ êµ¬í˜„í•´ë´¤ë‹¤. ë‹¤ìŒ ê¸€ì—ì„œëŠ” YOLO v1 ëª¨ë¸ì„ ì‹¤ì œë¡œ í›ˆë ¨ì‹œì¼œë³´ë„ë¡ í•˜ê² ë‹¤.

ì¶œì²˜ : 

[aladdinperssonë‹˜ì˜ github repository](https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/object_detection/YOLO)

ê°œì¸ ë¸”ë¡œê·¸ (http://herbwood.tistory.com/14)
