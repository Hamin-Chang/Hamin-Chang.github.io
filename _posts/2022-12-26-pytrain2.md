---
title : '[DL/Pytorch] 파이토치로 학습하기2 - 파라미터 최적화 🌡️'
layout: single
toc: true
toc_sticky: true
categories:
  - pytorchBasic
---

## 파이토치 모델이 학습하는 과정(자동미분,훈련,검증,과적합)

저번글([**링크**](https://hamin-chang.github.io/pytorchbasic/pytrain1/))에서는 간단한 예제를 통해서 파이토치의 역전파에 대해 알아봤다. 연쇄법칙을 사용해서 미분을 역방향으로 전파하는 방법을 통해 w와b를 내부 파라미터로 가지는 모델과 손실에 대한 합성함수의 기울기를 계산했었다. 이 계산은 우리가 다루는 모든 함수가 미분 가능하다는 전제가 필요하다. 

모델이 미분이 가능하다고 하면 수백만개의 파라미터를 가지는 복잡한 경우라도 파라미터에 대해 손실값의 기울기를 계산하고 미분에 대한 해석 가능한 표현식을 작성해서 단번에 계산이 가능하다. 하지만, 보통 모델의 함수의 미분에 대한 해석 가능한 표현식을 작성하는 일은 쉽지 않은 일이다.

### 1. 기울기 자동 계산
하지만 파이토치에는 **자동미분(autograd)** 기능이 있다! 파이토치 텐서는 흥미로운 성질이 하나 있는데, 바로 파이토치 텐서는 자신이 어느 텐서에서 어떤 연산을 수행해서 만들어진 텐서인지 기억하고 있다는 것이다. 이러한 성질은 자연스럽게 미분을 최초 입력까지 적용해 올라갈 수 있게 만들고, 그 결과 자동으로 모델에서 미분을 도출할 수가 있다. 순방향 식이 주어지기만 하면 아무리 복잡한 모델 함수라도 파이토치는 입력 파라미터와 관련해 표현식에 대한 기울기를 자동적으로 제공해준다.

먼저 이전 글에서 사용한 온도 문제 데이터와 모델(선형 함수), 손실 함수를 불러와서 자동 미분을 적용해보자.


```python
import torch
t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0] # 섭씨 온도
t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4] # 미지의 온도
t_c = torch.tensor(t_c) # 리스트를 텐서로 변환
t_u = torch.tensor(t_u)
t_un = t_u * 0.1
def model(t_u,w,b): # 차례대로 입력텐서, 가중치 파라미터, 편향값 파라미터
  return w * t_u + b 

def loss_fn(t_p, t_c): # 차례대로 출력값 , 정답값
  squared_diffs = (t_p - t_c)**2
  return squared_diffs.mean()
```


```python
params = torch.tensor([1.0,0.0], requires_grad=True) # 파라미터 텐서 초기화
```

위의 코드에서 required_grad=True 인자는 params에 가해지는 연산의 결과로부터 만들어지는 모든 텐서들이 만들어지기까지 그 사이에 있는 모든 함수에 접근할 수 있도록 파이토치에게 요청하는 인자이다. 이 함수들이 미분 가능한 경우, 미분 값은 params 텐서의 grad 속성으로 자동 기록된다.

일반적으로 모든 파이토치 텐서는 None 값의 grad 속성을 가지는데,


```python
params.grad is None
```




    True



grad 값을 얻으려면 requires_grad = True로 지정하고 모델을 호출해서 손실값을 구한 다음 loss 텐서에 대해 backward를 호출하면 된다.


```python
loss = loss_fn(model(t_u,*params),t_c)
loss.backward()

params.grad
```




    tensor([4517.2969,   82.6000])



이제 params의 grad는 손실값을 params의 각 요소에 대한 미분한 값을 포함하고 있다.

![autograd1](https://user-images.githubusercontent.com/77332628/209557165-59a7c069-1518-4bf8-ad98-3865db661c09.png)

(출처 : https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html)

loss를 계산할 때 w와b가 기울기를 요구하는 경우, 위의 이미지처럼 파이토치는 연산을 노트로 하는 자동미분 그래프를 만들고 이후 loss.backward()를 호출하면 파이토치는 화살표의 역방향으로 그래프를 거꾸로 따라가면서 기울기를 계산한다. 

#### 1.1 미분 함수 누적하기
텐서의 수 또는 합성 함수의 다양성에 상관 없이 requires_grad = True로 설정할 수 있다. 이런 경우에 파이토치는 연쇄적으로 연결된 함수들을 거쳐서 손실에 대한 계산한 미분값을 텐서(위 이미지의 말단 노드 w,b)에 누적한다. **저장(store)**이 아니라 **누적(accumulate)**이라는 표현이라는 것에 명심하자! backward 호출은 미분을 말단 노드에 누적시키기 때문에 만약 앞서 backward가 호출되었다면 손실이 다시 계산되고 backward가 다시 호출되고 각 말단 노드의 기울기 값이 이전 반복문이 돌아갈 때 계산 됏던 기존값에 합쳐져서 부정확한 grad 값을 초래하게 된다.

이를 방지하려면 다음의 코드로 **명시적으로 기울기를 0으로 초기화**해야 한다. (파이토치가 자동으로 0으로 초기화해주지 않는다!)


```python
if params.grad is not None:
  params.grad.zero_() # zero에 _가 붙었기 때문에 텐서가 아예 바뀐다!
```

이제 훈련 루프를 정의하는 함수를 다시한번 정의해보자!


```python
def training_loop(n_epochs, learning_rate, params, t_u,t_c):
  for epoch in range(1,n_epochs+1):
    if params.grad is not None:  # loss.backward() 호출 전 아무 위치 가능
      params.grad.zero_() 
    
    t_p = model(t_u, *params)
    loss = loss_fn(t_p, t_c)
    loss.backward()

    with torch.no_grad():  # 이 부분은 처음 보지만 이 글 밑에서 다룬다.
      params -= learning_rate * params.grad

    if epoch % 500 ==0 :
      print(f'Epoch {epoch}, Loss {float(loss)}')
  
  return params
```

잘 작동되는지 훈련 루프를 돌려보자.


```python
training_loop(n_epochs=5000,
              learning_rate=1e-2,
              params = torch.tensor([1.0,0.0], requires_grad=True),
              t_u = t_un, # 정규화된 입력 사용
              t_c = t_c)
```

    Epoch 500, Loss 7.860115051269531
    Epoch 1000, Loss 3.828537940979004
    Epoch 1500, Loss 3.092191219329834
    Epoch 2000, Loss 2.957697868347168
    Epoch 2500, Loss 2.933133840560913
    Epoch 3000, Loss 2.9286484718322754
    Epoch 3500, Loss 2.9278297424316406
    Epoch 4000, Loss 2.9276793003082275
    Epoch 4500, Loss 2.927651882171631
    Epoch 5000, Loss 2.9276468753814697





    tensor([  5.3671, -17.3012], requires_grad=True)



이전 글에서의 결과와 동일하다! 이제는 파이토치에게 자동적인 미분 계산을 맡길 수 있다.

### 2. 옵티마이저 골라쓰기
위의 코드에서는 우리는 기본 버전의 경사 하강을 사용했는데, 이는 단순한 경우에는 잘 동작하지만 모델이 복잡하면 다른 방법의 최적화 기법을 사용해야한다. 파이토치는 사용자 코드로부터 최적화 관련된 전략을 추상화시켜주는 방식을 제공한다. 파이토치는 매번 파라미터를 직접 조정하는 지루한 작업을 대신 해준다. torch에 있는 optim이라는 서브 모듈에는 다양한 옵티마이저들이 있다. optim의 옵티마이저들의 목록은 다음과 같다.


```python
import torch.optim as optim

dir(optim)
```




    ['ASGD',
     'Adadelta',
     'Adagrad',
     'Adam',
     'AdamW',
     'Adamax',
     'LBFGS',
     'NAdam',
     'Optimizer',
     'RAdam',
     'RMSprop',
     'Rprop',
     'SGD',
     'SparseAdam',
     '__builtins__',
     '__cached__',
     '__doc__',
     '__file__',
     '__loader__',
     '__name__',
     '__package__',
     '__path__',
     '__spec__',
     '_functional',
     '_multi_tensor',
     'lr_scheduler',
     'swa_utils']



모든 옵티마이저 생성자는 첫번째 인수로 파라미터 리스트(보통 requires_grad = True인 텐서)를 받는다. 옵티마이저에 전달된 파라미터는 옵티마이저 객체 내부에 유지되고, 파라미터를 조정하고 grad에 접근할 때 사용된다. 옵티마이저는 생성자에 전달됐던 파라미터의 모든 grad를 0으로 만드는 **zero_grad 매서드**와 옵티마이저별로 구현된 최적화 전략에 따라 파라미터를 조정하는 **step 매서드**를 제공한다.

#### 2.1 확률적 경사 하강 옵티마이저 (SGD)
SGD는 확률적 경사하강의 약자인데, SGD의 기울기는 *미니배치*라고 불리는 여러 데이터 샘플 중에서 **확률적**(임의)으로 뽑은 일부에 대해 평균을 계산해서 얻는다. 다만 옵티마이저는 손실값이 모든 샘플로부터 얻은 것인지 일부를 임의로 선택해서 얻은 것인지 모르기 때문에 순정 버전의 경사 하강과 알고리즘적으로는 동일하다. 

SGD 옵티마이저 인스턴스를 생성하고 옵티마이저를 돌려보자.


```python
params = torch.tensor([1.0,0.0], requires_grad=True)
learning_rate = 1e-5 
optimizer = optim.SGD([params],lr=learning_rate) # 옵티마이저 인스턴스
 
t_p = model(t_u, *params)
loss = loss_fn(t_p,t_c)
loss.backward()

optimizer.step()

params
```




    tensor([ 9.5483e-01, -8.2600e-04], requires_grad=True)



이제 기울기를 0으로 초기화하는 zero_grad 매서드를 backward 호출 전에 추가해서 훈련 루프에 옵티마이저 코드를 넣어서 돌려보자.


```python
params = torch.tensor([1.0,0.0], requires_grad=True)
learning_rate = 1e-5 
optimizer = optim.SGD([params],lr=learning_rate) # 옵티마이저 인스턴스
 
t_p = model(t_u, *params)
loss = loss_fn(t_p,t_c)

optimizer.zero_grad() # backward 앞에만 위치하면 OK
loss.backward()
optimizer.step()

params
```




    tensor([ 9.5483e-01, -8.2600e-04], requires_grad=True)




```python
def training_loop(n_epochs, optimizer, params, t_u,t_c):
  for epoch in range(1,n_epochs+1):
    t_p = model(t_u, *params)
    loss = loss_fn(t_p, t_c)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if epoch % 500 ==0 :
      print(f'Epoch {epoch}, Loss {float(loss)}')
  
  return params
```


```python
params = torch.tensor([1.0,0.0],requires_grad=True) # 파라미터 초기화
learning_rate = 1e-2
optimizer = optim.SGD([params],lr=learning_rate)

training_loop(n_epochs=5000,
              optimizer=optimizer,
              params=params,
              t_u=t_un,
              t_c=t_c)
```

    Epoch 500, Loss 7.860119819641113
    Epoch 1000, Loss 3.828537940979004
    Epoch 1500, Loss 3.092191219329834
    Epoch 2000, Loss 2.957697868347168
    Epoch 2500, Loss 2.933133840560913
    Epoch 3000, Loss 2.9286484718322754
    Epoch 3500, Loss 2.9278297424316406
    Epoch 4000, Loss 2.9276793003082275
    Epoch 4500, Loss 2.927651882171631
    Epoch 5000, Loss 2.9276468753814697





    tensor([  5.3671, -17.3012], requires_grad=True)



#### 2.2 다른 옵티마이저 사용해보기
Adam 옵티마이저를 사용해볼건데, 간단히 말하자면 Adam은 학습률이 동적으로 변하는 옵티마이저이기 때문에 파라미터 비율 조정에도 덜 영향 받기 때문에 정규화되지 않은 t_u 입력을 사용하고 학습률을 1e-1로 올려도 학습에 지장이 없다. Adam을 사용하기 위해서는 Adam을 위한 인스턴스로 만들면 된다. 정말 간단하다!


```python
params = torch.tensor([1.0,0.0],requires_grad=True) # 파라미터 초기화
learning_rate = 1e-1 # 학습률 올림
optimizer = optim.Adam([params],lr=learning_rate)

training_loop(n_epochs=2000,
              optimizer=optimizer,
              params=params,
              t_u=t_u, # 정규화X 입력 사용
              t_c=t_c)
```

    Epoch 500, Loss 7.612900257110596
    Epoch 1000, Loss 3.086700439453125
    Epoch 1500, Loss 2.928579092025757
    Epoch 2000, Loss 2.9276442527770996





    tensor([  0.5367, -17.3021], requires_grad=True)



### 3. 훈련, 검증 그리고 과적합
우리는 옵티마이저에게 주어진 데이터에 대한 손실을 최소화하라고 요청하는데, 우리가 훈련 손실을 구할 때 사용했던 데이터와 다른 데이터를 사용하면 기대했던 것보다 높은 손실을 일으킬 수 있다. 이런 현상을 **과적합 overfitting**이라고 한다. 과적합을 방지하기 위해선 먼저 과적합이 일어날 수 있음 인지해야 한다. 먼저 데이터를 일부 따로 **검증셋 (validation set)**으로 떼어놓고 남은 데이터를 **훈련셋 (training set)**으로 분리한다. 

#### 3.1 데이터셋 나누기
먼저 t_u와 t_c를 같은 식으로 섞어서 만들어진 텐서를 훈련셋과 검증셋으로 나누자.

randperm 함수는 색인 순열을 찾기 위해 텐서 요소를 섞었을 때의 인덱스 리스트를 반환한다.


```python
n_samples = t_u.shape[0]
n_val = int(0.2*n_samples) # 전체 데이터의 20%만 검증셋으로 떼어낸다.

shuffled_indices = torch.randperm(n_samples)

# 인덱스 텐서
train_indices = shuffled_indices[:-n_val]
val_indices = shuffled_indices[-n_val:]

train_t_u = t_u[train_indices]
train_t_c = t_c[train_indices]

val_t_u = t_u[val_indices]
val_t_c = t_c[val_indices]

train_t_un = 0.1 * train_t_u
val_t_un = 0.1 * val_t_u
```

### 3.2 훈련셋으로 훈련 손실 구하고, 검증셋으로 일반화하기
훈련 손실값은 모델이 훈련셋에 얼마나 잘 맞춰졌는지를 알려준다. 예를 들어, 만약 지금 다루고 있는 온도 문제의 데이터를 로그 범위로 측정했다면 우리의 선형 모델은 데이터에 잘 맞지 않아서 훈련 손실이 0에 가까워지기 전에 줄어드는 것을 멈췄을 것이다. **[규칙1]** **훈련 손실이 줄어들지 않는다면 데이터에 비해 모델이 너무 단순하거나 모델의 출력을 설명할 만한 데이터가 아닐 가능성이 있다.**

검증셋으로 돌아가보면, 만일 검증셋에 대한 손실이 훈련셋에서처럼 줄어들지 않는다면, 모델이 훈련을 통해 바라본 데이터에 대해서는 잘 맞아서 발전하지만 훈련셋에서는 보지 못한 , 처음보는 데이터에는 맞지 않아서 검증 손실 값이 크게 나올 것이다. **[규칙2] 훈련 손실과 검증 손실 사이에 차이가 크게 발생한다면 과적합한 것이다.** 즉, 모델이 훈련셋에 과도하게 맞춰져서 일반화에 실패했다는 것이다. 

아래 이미지의 왼쪽 이미지는 [규칙1]에 관한 이미지고, 오른쪽은 [규칙2]에 관한 과적합된 상황이다.

![autograd2](https://user-images.githubusercontent.com/77332628/209557169-2e7f3ce9-410c-49d2-90a4-196fef6e0926.png)

출처(https://medium.com/@rdhawan201455/overfitting-and-underfitting-bug-in-ml-models-97f2da56df30)

그럼 과적합에 대한 개선 방법은 무엇일까? 먼저 개선하려면 충분한 데이터가 주어졌는지 확인해야한다. 데이터를 충분히 모았다면 다음으로는 모델이 각 훈련 데이터에 대해 적합한 수준으로 맞춰질 수 있는지 확인해야한다. 여러 방법 중 하나는 손실 함수에 **페널티항**을 두어서 모델의 적합이 더 부드럽게 만들어지도록 하는 방법이 있다. 다른 방법으로는 입력 데이터에 노이즈를 더해서 각 훈련 데이터 사이에 새로운 데이터 포인트를 인위적으로 만들어서 모델로 하여금 이 노이즈 데이터에도 맞춰지도록 하는 방법도 있다. 이외에도 여러 방법이 있지만 이 두방법과 유사하다. 일단 우리는 모델의 단순화를 시도해 볼것이다.

그럼 우리는 고민을 하게 된다. 모델이 훈련 데이터에 충분히 적합해질 만큼 충분한 능력을 갖추기도 해야하고, 모델의 과적합도 방지해야 한다. 그래서 파라미터의 측면에서 적합한 신경망 사이즈를 고르는 것은 두 단계로 진행한다. 먼저 충분히 적합될 때까지 사이즈를 늘리다가, 과적합하지 않을 때까지 규모를 줄이는 것이다.

이제 훈련 루프에 훈련 셋과 검증 셋을 나누어서 넣고, 각 에포크마다 부가적으로 검증셋에 대한 손실을 계산해서 과적합을 하고 있는지 파악하는 부분을 추가해서 훈련 루프를 돌려보자.


```python
def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u,
                  train_t_c, val_t_c):
    for epoch in range(1, n_epochs + 1):
        train_t_p = model(train_t_u, *params) 
        train_loss = loss_fn(train_t_p, train_t_c)
                             
        val_t_p = model(val_t_u, *params) 
        val_loss = loss_fn(val_t_p, val_t_c)
        
        optimizer.zero_grad()
        train_loss.backward() 
        # 검증 데이터로는 학습하면 안되기 때문에 val_loss.backward()는 없다.
        optimizer.step()

        if epoch <= 3 or epoch % 500 == 0:
            print(f"Epoch {epoch}, Training loss {train_loss.item():.4f},"
                  f" Validation loss {val_loss.item():.4f}")
            
    return params
```


```python
params = torch.tensor([1.0, 0.0], requires_grad=True)
learning_rate = 1e-2
optimizer = optim.SGD([params], lr=learning_rate)

training_loop(
    n_epochs = 3000, 
    optimizer = optimizer,
    params = params,
    train_t_u = train_t_un, 
    val_t_u = val_t_un, 
    train_t_c = train_t_c,
    val_t_c = val_t_c)
```

    Epoch 1, Training loss 53.5719, Validation loss 200.9305
    Epoch 2, Training loss 25.9376, Validation loss 122.3720
    Epoch 3, Training loss 20.5573, Validation loss 97.6301
    Epoch 500, Training loss 7.3756, Validation loss 33.8520
    Epoch 1000, Training loss 4.1195, Validation loss 16.8417
    Epoch 1500, Training loss 3.2382, Validation loss 10.3194
    Epoch 2000, Training loss 2.9997, Validation loss 7.5561
    Epoch 2500, Training loss 2.9351, Validation loss 6.2891
    Epoch 3000, Training loss 2.9176, Validation loss 5.6760





    tensor([  4.9319, -15.0931], requires_grad=True)



훈련셋과 검증셋의 데이터 양은 동일하지 않다. 검증셋의 데이터 크기가 작기 때문에 검증셋에서의 손실값은 의미 있을 수준 정도이다. 결과에서 모든 경우에 수십 배 이상은 아니더라도 그래프상에서 검증 손실은 훈련 손실보다는 크다는 것을 명심하자. 훈련셋에 의해서 모델의 파라미터가 조정이 되기 때문에 통상적으로 모델이 훈련셋에서 더 잘 작동하는 것은 정상적인 것이다. 모델의 궁극적인 목표는 훈련 손실과 검증 손실이 둘 다 줄어드는 것이다. 다음의 이미지를 살펴보면, 첫 이미지는 학습이 되지 않는 모델의 결과이고, 두번째는 이상적인 모델의 결과 , 마지막 이미지는 과적합된 모델의 손실 함수이다.

![autograd3](https://user-images.githubusercontent.com/77332628/209557170-c9b2fd62-26ec-455e-a4fa-cde369ae2638.png)



출처 (https://livebook.manning.com/book/deep-learning-with-javascript/chapter-7/v-6/150)

### 4. 자동미분 끄기
위에서 작성한 훈련루프에서 생각해볼 부분이 있다. 우리는 검증셋에 대해선 더이상 파라미터를 조정하지 않기 때문에 val_loss에 대해서는 backward()를 호출하지 않는데, 그러면서 처음에 연산 그래프를 만든 이유가 뭘까? 최적화된 자동미분 그래프 생성에는 불필요한 비용이 들어간다. 파라미터가 수백만개에 이르는 모델이라면 낭비하는 비용도 더 커진다. 이를 방지하기 위해서 파이토치는 torch.no_grad를 통해서 필요하지 않을 때 자동미분을 끌 수 있게 해준다. 지금은 체감이 잘 안되겠지만, 더 큰 모델에서는 이 비용을 아끼는 것이 유의미하다. 자동미분을 끄고 훈련 루프를 다시 정의해보자.


```python
def training_loop(n_epochs,optimizer,params,train_t_u,val_t_u,train_t_c,val_t_c):
  for epoch in range(1,n_epochs+1):
    train_t_p = model(train_t_u,*params)
    train_loss = loss_fn(train_t_p,train_t_c)

    with torch.no_grad(): # 자동미분 끄는 콘텍스트 관리자
      val_t_p = model(val_t_u,*params)
      val_loss = loss_fn(val_t_p,val_t_c)
      assert val_loss.requires_grad == False # 이 블록 내에서 requires_grad=False로 설정을 강제한다는 상황을 점검

    optimizer.zero_grad()
    train_loss.backward()
    optimizer.step()
```

set_grad_enabled를 통한 콘텍스트 설정으로는 autograd를 켤지 끌지를 제어할 수 있다. 불리언 표현으로 현재 훈련 모드인지, 추론 모드인지를 나타낸다. 예를 들어, calc_forward 함수를 정의하고 데이터를 입력 받아서 model과 loss_fn을 실행하되, is_train 인자에 따라서 자동미분의 사용 여부를 설정할 수 있다.


```python
def calc_forward(t_u,t_c,is_train):
  with torch.set_grad_enabled(is_train):
    t_p = model(t_u,*params)
    loss = loss_fn(t_p,t_c)
  return loss
```

이번 글에서는 저번 글에 이어서 온도 문제를 다루면서 파이토치가 모델의 파라미터를 조정하는 방식에 대해 알아보았다. 이번 글에서는 파이토치로 모델을 최적화시키는데에 집중했다. 다음 글에서 부터는 본격적인 파이토치로 신경망을 다루는 방법에 대해 소개하겠다.
