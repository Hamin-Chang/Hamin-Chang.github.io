---
title : '[DL/Pytorch] 파이토치로 분류기 구현1 - 새vs비행기 ✈️'
layout: single
toc: true
toc_sticky: true
categories:
  - pytorchBasic
---

## 파이토치로 구현하는 분류기(데이터 로드, 텐서 변환, 데이터 정규화)


이번 글에서는 이미지 인식을 위한 모델을 직접 구축하면서 신경망에 대한 기초를 더 다져보도록 한다. 크기는 작지만 엄청난 양의 데이터셋을 사용해서 이미지 분류를 해본다. 먼저 이미지 분류에 사용할 데이터셋을 다운하자.
### 1. 이미지 데이터 로드하기
이번 글에서는 CIFAR-10 데이터셋을 사용하는데, 이는 지난 십여 년간 컴퓨터 비전에 고전적으로 사용되는 데이터셋이다. CIFAR-10은 32x32 크기의 컬러 이미지 6만개로 구성되어있고 이미지마다 0~9의 정수 레이블이 매겨져 있다. 0은 비행기, 1은 자동차, 2는 새, 3은 고양이, 4는 사슴, 5는 강아지, 6은 개구리, 7은 말, 8은 배, 9는 트럭이다. CIFAR-10 데이터 다운로드는 torchvision을 import하고 dataset 모듈로 실행한다. 



```python
from torchvision import datasets
data_path = '/content/cifar10' # 데이터 저장 경로
cifar10 = datasets.CIFAR10(data_path,train=True,download=True) # 훈련 데이터용 객체를 만든다. 데이터가 없으면 자동으로 다운로드
cifar10_val = datasets.CIFAR10(data_path, train=False,download=True) # train=False로 검증용 데이터 다운로드


class_names = ['airplane','automobile','bird','cat','deer',
               'dog','frog','horse','ship','truck']

from matplotlib import pyplot as plt

fig = plt.figure(figsize=(8,3))
num_classes = 10
for i in range(num_classes):
    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])
    ax.set_title(class_names[i])
    img = next(img for img, label in cifar10 if label == i)
    plt.imshow(img)
plt.show()
```

    Files already downloaded and verified
    Files already downloaded and verified



    
![nn1](https://user-images.githubusercontent.com/77332628/210139058-db1fc5ea-2090-4d21-b124-00664e0bc647.png)
    


datasets 서브모듈은 CIFAR10 데이터 뿐만 아니라 MNIST, CIFAR-100, SVHN등의 컴퓨터 비전에서 많이 사용되는 데이터셋에 접근할 수 있다. 각 경우에 데이터셋은 torch.utils.data.Dataset의 서브클래스로 반환된다. 이는 cifar10 인스턴스의 메소드를 분석해보면 기본 클래스로 포함된 것을 알 수 있다.


```python
type(cifar10).__mro__
```




    (torchvision.datasets.cifar.CIFAR10,
     torchvision.datasets.vision.VisionDataset,
     torch.utils.data.dataset.Dataset,
     typing.Generic,
     object)



torch.utils.data.Dataset의 서브클래스가 된다는 것이 무슨 의미인지 알아보자. 다음 이미처럼 Dataset은 실제 관찰하면서 __ len __과 __ getitem __이 반환해야 할 것들을 반환하도록 하는 객체이다. __ len __은 데이터셋의 아이템 수를 반환하고, __ getitem __은 샘플과 레이블로 이루어진 아이템을 반환한다. 

이미지1

출처(https://livebook.manning.com/concept/deep-learning/_-_-getitem-_-_)

실제 사용시 __ len __ 메소드가 구현된 파이썬 객체이면 len의 인자로도 사용 가능하다.


```python
len(cifar10)
```




    50000



Dataset에서 __ getiem __ 메소드가 구현되어 있기 때문에 개별 아이템에 접근할 때 표준 서브스크립트에 해당하는 색인용 튜플과 리스트를 사용할 수 있다. 다음은 '자동차'에 해당하는 레이블인 1인 PIL(Python Image Library) 형식의 이미지를 얻는 코드다.


```python
img, label = cifar10[99]
img, label, class_names[label]
```




    (<PIL.Image.Image image mode=RGB size=32x32 at 0x7F3AE152EA60>,
     1,
     'automobile')



위의 결과는 순서대로 PIL 형식의 이미지, 이미지 레이블, 레이블 이름을 반환한다.

CIFAR10 데이터셋은 RGB PIL 이미지 객체이기 때문에 바로 그릴 수 있다.


```python
plt.imshow(img)
plt.show()
```


    
![nn2](https://user-images.githubusercontent.com/77332628/210139059-420a8319-7769-4f7d-82c8-280c720d22c6.png)
    


### 2. 데이터 변환
이제 PIL 이미지를 파이토치 텐서로 변환하자. torchvision.transforms라는 모듈 중 ToTensor라는 객체를 사용할건데, 이는 numpy 배열과 PIL 이미지를 텐서로 바꿔준다. 뿐만 아니라 출력 텐서의 차원 레이아웃을 CxHxW로 맞춰준다. 한번 사용해보자.


```python
from torchvision import transforms

to_tensor = transforms.ToTensor()
img_t = to_tensor(img)
img_t.shape
```




    torch.Size([3, 32, 32])



이미지가 3x32x32 크기의 텐서로 바뀌었고 RGB 세개의 채널을 가지는 이미지가 됐다. 참고로 label 값은 변동 없이 정수값이 유지된다. 물론, to_tensor 객체 자체를 dataset.CIFAR10의 인자로 전달하는 것도 가능하다.


```python
tensor_cifar10 = datasets.CIFAR10(data_path, train=True, download=False, transform=transforms.ToTensor())
```

이 dataset의 요소는 이제 이미지가 아닌 텐서를 반환한다.


```python
img_t, _ = tensor_cifar10[99]
type(img_t)

```




    torch.Tensor



또한 PIL 이미지 값은 0 ~ 255 범위이지만 ToTensor로 변환하면 데이터가 부동소수점 0.0 ~ 1.0 사이로 범위가 줄어든다.





```python
img_t.min() , img_t.max()
```




    (tensor(0.), tensor(1.))



### 3. 데이터 정규화
변환 기능은 transforms.Compose로 여러 변환을 엮어서 사용할 수 있다. 잘 사용하면 정규화와 데이터 증강도 데이터 로딩과 함께 수행할 수 있다. 데이터 정규화로 각 채널이 평균값 0과 단위 표준편차를 가지게 만들 수 있다. -1과 1 혹은 -2와 2 사이에서 선형인 활성 함수를 고르고 데이터를 같은 범위에서 평균을 가지게 한다면 뉴런은 0이 아닌 기울기를 가지게 되어서 학습을 빨리 할 수 있고, 또한 각 채널을 정규화 해서 동일한 분산을 가지게 한다면 채널 정보가 동일한 학습률로 경사하강을 통해 섞이고 업데이트 되는 것을 보장할 수 있다. 정규화는 transforms.Normalize를 이용해서 할 수 있는데, 이때 mean과 stdev는 계산해주지 않기 때문에 따로 계산해야 한다.

CIFAR10 데이터셋은 크기가 작기 때문에 메모리 내에서 모든 변환을 할 수 있다. 추가 차원을 만들어서 데이터셋이 반환하는 모든 텐서를 쌓아 놓자.


```python
import torch
imgs = torch.stack([img_t for img_t,_ in tensor_cifar10],dim=3)
```

이제 채널별로 평균과 표준편차를 계산한다.


```python
print(imgs.view(3,-1).mean(dim=1))
print(imgs.view(3,-1).std(dim=1))
```

    tensor([0.4914, 0.4822, 0.4465])
    tensor([0.2470, 0.2435, 0.2616])


이제 transforms.Normalize로 정규화를 진행하고, ToTensor 변환에 이어 붙이자.


```python

transformed_cifar10 = datasets.CIFAR10(data_path, train=True,download=False,
                                       transform=transforms.Compose([transforms.ToTensor(),
                                                                     transforms.Normalize((0.4914, 0.4822, 0.4465),
                                                                                          (0.2470, 0.2435, 0.2616))
                                                                     ]))
```

정규화를 했기 때문에 데이터를 그려도 원본과는 많이 다른 모습이 출력된다.


```python
img_t, _ = transformed_cifar10[99]
plt.imshow(img_t.permute(1,2,0))
plt.show()
```

    WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).



    

![nn3](https://user-images.githubusercontent.com/77332628/210139060-4ad403c6-2a54-4948-b0bc-84b1fe0ea5d2.png)
    


이번 글에서는 CIFAR-10 데이터셋을 로드하고, 로드한 데이터를 텐서로 변환하고, 정규화하는 방법에 대해 알아봤다. 다음 글에서 이어서 본격적으로 CIFAR-10 데이터셋을 이용해서 새와 비행기를 구분하는 신경망을 구축해볼 것이다.
