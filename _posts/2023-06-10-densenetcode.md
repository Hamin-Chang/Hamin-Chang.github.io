---
title : '[IC/Pytorch] íŒŒì´í† ì¹˜ë¡œ DenseNet êµ¬í˜„í•˜ê¸° ğŸ•¸ï¸' 
layout: single
toc: true
toc_sticky: true
categories:
  - ICCode
---


## Pytorchë¡œ DenseNet êµ¬í˜„í•˜ê¸°

ì´ë²ˆ ê¸€ì—ì„œëŠ” ì‹¤ì œ pytorch ì½”ë“œë¡œ DenseNetì„ êµ¬í˜„í•´ë³¸ë‹¤. DenseNetì— ëŒ€í•œ ê°œë…ì€ [**<U>DenseNet ë…¼ë¬¸ ë¦¬ë·°</U>**](https://hamin-chang.github.io/cv-imageclassification/DenseNet/)ë¥¼ ì°¸ê³ í•˜ê¸¸ ë°”ë€ë‹¤. pytorch DenseNet ì½”ë“œëŠ” [**<U>weiaicunzai's repository</U>**](https://github.com/weiaicunzai/pytorch-cifar100/blob/master/models/densenet.py)ë¥¼ ì°¸ê³ í–ˆë‹¤.

ì‹¤ì œ ë°ì´í„°ë¥¼ ì´ìš©í•´ì„œ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ê³¼ì •ì€ ìƒëµí•˜ê³  pytorch ì½”ë“œë¡œ êµ¬í˜„í•˜ëŠ” ê²ƒìœ¼ë¡œ ì´ ê¸€ì„ ë§ˆì¹˜ê² ë‹¤.


### 1. Bottleneck block

ê°€ì¥ ë¨¼ì € DenseNetì— ì‚¬ìš©ë˜ëŠ” Bottleneck blockì„ ì •ì˜í•œë‹¤.

ì´ë¯¸ì§€1

DenseNetì— ì‚¬ìš©ë˜ëŠ” Bottleneck êµ¬ì¡°ëŠ” íŠ¹ì´í•˜ê²Œ 1x1 conv ì—°ì‚°ì„ í†µí•´ì„œ 4 x growth rateê°œì˜ feature mapì„ ë§Œë“¤ê³  ê·¸ ë’¤ì— 3x3 convë¥¼ í†µí•´ì„œ growth rateê°œì˜ feature mapìœ¼ë¡œ ì¤„ì—¬ì¤€ë‹¤.


```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class Bottleneck(nn.Module):
    def __init__(self, in_channels, growth_rate):
        super().__init__()
        inner_channel = 4 * growth_rate
        
        self.bottle_neck = nn.Sequential(nn.BatchNorm2d(in_channels),
                                        nn.ReLU(inplace=True),
                                        nn.Conv2d(in_channels, inner_channel, kernel_size=1, bias=False),
                                        nn.BatchNorm2d(inner_channel),
                                        nn.ReLU(inplace=True),
                                        nn.Conv2d(inner_channel, growth_rate, kernel_size=3, padding=1, bias=False))
    
    def forward(self, x):
        return torch.cat([x, self.bottle_neck(x)], 1)
```

### 2. Transition Layer

pooling ì—­í• ì„ í•˜ëŠ” Transition layerë¥¼ ì •ì˜í•œë‹¤.


```python
class Transition(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.down_sample = nn.Sequential(nn.BatchNorm2d(in_channels),
                                        nn.Conv2d(in_channels, out_channels, 1, bias=False),
                                        nn.AvgPool2d(2, stride=2))
    
    def forward(self, x):
        return self.down_sample(x)
```

### 3. DenseNet

ì´ì œ Bottleneck blockê³¼ Transition layerë¥¼ ì´ìš©í•´ì„œ DenseNet ëª¨ë¸ì„ êµ¬ì¶•í•˜ëŠ” í´ë˜ìŠ¤ë¥¼ ì •ì˜í•œë‹¤.

ë…¼ë¬¸ì—ì„œì™€ ë§ˆì°¬ê°€ì§€ë¡œ growth rate $k=12$ì™€ compression factor $Î¸=0.5$ë¡œ ì„¤ì •í•œë‹¤.


```python
class DenseNet(nn.Module):
    def __init__(self, block, nblocks, growth_rate=12, reduction=0.5, num_class=100): # cifar-100 ë°ì´í„°ë¡œ í•™ìŠµ ê°€ì •
        super().__init__()
        self.growth_rate = growth_rate
        
        inner_channels = 2*growth_rate
        
        self.conv1 = nn.Conv2d(3, inner_channels, kernel_size=3, padding=1, bias=False)
        self.features = nn.Sequential()
        
        
        
        for index in range(len(nblocks)-1):
            self.features.add_module('dense_block_layer_{}'.format(index), self._make_dense_layers(block,inner_channels,nblocks[index]))
            inner_channels += growth_rate * nblocks[index]
            out_channels = int(reduction * inner_channels)
            self.features.add_module('transition_layer_{}'.format(index), Transition(inner_channels, out_channels))
            inner_channels = out_channels
        
        self.features.add_module('dense_block{}'.format(len(nblocks)-1), self._make_dense_layers(block, inner_channels, nblocks[len(nblocks)-1]))
        inner_channels += growth_rate * nblocks[len(nblocks)-1]
        self.features.add_module('bn', nn.BatchNorm2d(inner_channels))
        self.features.add_module('relu', nn.ReLU(inplace=True))
        
        self.avgpool = nn.AdaptiveAvgPool2d((1,1))
        self.linear = nn.Linear(inner_channels, num_class)
        
    def forward(self,x):
        output = self.conv1(x)
        output = self.features(output)
        output = self.avgpool(output)
        output = output.view(output.size()[0], -1)
        output = self.linear(output)
        return output
    
    def _make_dense_layers(self, block, in_channels, nblocks):
        dense_block = nn.Sequential()
        for index in range(nblocks):
            dense_block.add_module('bottle_neck_layer_{}'.format(index), block(in_channels, self.growth_rate))
            in_channels += self.growth_rate
        
        return dense_block
```

ì´ì œ DenseNet í´ë˜ìŠ¤ì˜ ì¸ìˆ˜ ì¤‘ blockìˆ˜ì™€ growth_rateë¥¼ ë°”ê¿”ê°€ë©° ëª¨ë¸ì„ ìƒì„±í•˜ë©´ ëœë‹¤. ìš°ë¦¬ëŠ” densenet121ì„ ìƒì„±í•œ í›„ ì˜ ì‘ë™í•˜ëŠ”ì§€ ì„ì˜ì˜ inputì„ ë„£ì–´ë³´ê³  ëª¨ë¸ì„ ëŒë ¤ë³´ê³  ê¸€ì„ ë§ˆë¬´ë¦¬í•œë‹¤.


```python
def densenet121():
    return DenseNet(Bottleneck, [6,12,24,16], growth_rate=32)

x = torch.randn(3, 3, 64, 64)
model = densenet121()
output = model(x)
print(output.size())
```

    torch.Size([3, 100])


ì¶œì²˜ ë° ì°¸ê³ ë¬¸í—Œ

1. https://github.com/weiaicunzai/pytorch-cifar100/blob/master/models/densenet.py
2. https://velog.io/@lighthouse97/DenseNet%EC%9D%98-%EC%9D%B4%ED%95%B4
