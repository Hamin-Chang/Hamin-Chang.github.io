---
layout: single
title:  "[CV/KERAS] 딥러닝 아키텍처 - 직관 기르기 🏗️"
toc: true
toc_sticky: true
categories:
  - kerasCV
---


## 컨브넷 아키텍처 패턴 (잔차연결, 배치 정규화, 깊이별 분리 합성곱)





### 5.1 최신 컨브넷 아키텍처



#### 5.1.0 들어가며

모델의 '아키텍처'는 모델을 만드는 데 사용되는 일련의 선택이다. 사용할 층, 층의 설정, 층을 연결하는 방법등을 선택하는 것이 모델의 '아키텍처'인 것이다. 모델 아키텍처가 모델의 성공과 실패를 가름하는 경우가 많다. 좋은 모델 아키텍처는 탐색 공간의 크기를 줄이거나 탐색 공간의 좋은 위치에 쉽게 수렴할 수 있는 구조다. 사실 모델 아키텍처는 과학보다는 예술에 가깝다고들 말한다. 그만큼 많은 경험이 필요하고 , 전문가들의 직관이 많이 필요하기 때문이다. 전문가는 다양한 실전 경험을 통해 얻은 능력인 **패턴 매칭**에 의존한다. 



이번 절에서는 다음의 핵심적인 컨브넷 아키텍처의 모범 사례들을 알아본다. 



*   **잔차 연결** (residual connection) 

*   **배치 정규화** (batch normalization)

*   **분리 합성곱** (seperable convolution)

 

이런 층들을 사용하는 방법들을 익히면 효율적인 이미지 모델을 구축하는데 큰 도움이 된다. 이번 글에서는 이런 기술들을 *강아지 vs 고양이* 분류 문제에 적용해본다.



#### 5.1.1 모듈화,계층화 그리고 재사용

복잡한 시스템을 단순하게 만드는 일반적으로 적용할 수 있는 방법이 있다. 복잡한 구조를 **모듈화**하고, 모듈들을 **계층화**하고, 같은 모듈을 여러곳에 **재사용**하는 것이다. 이는 '아키텍처'라는 용어가 사용되는 거의 모든 영역에 있는 시스템 구조의 기초가 된다. 이를 딥러닝에 적용하면, 딥러닝 모델 아키텍처는 모듈화, 계층화, 재사용을 영리하게 활용하는 것이다. 인기있는 모든 컨브넷 아키텍처는 층으로만 구성되어 있지 않고 반복되는 층의 그룹(블록 or 모듈)으로 구성되어 있다. 또한, 대부분의 컨브넷은 피라미드와 같은 계층 구조를 가지는 경우가 많다. 예를 들어, 이전 글에서 만든 첫번째 컨브넷에서 사용한 합성곱 필터 개수는 32,64,128개로 층이 깊어질수록 늘어난다.(반면 특성 맵의 크기는 줄어든다.) 아래 이미지처럼 VGG16 모델의 블록에서도 동일한 패턴을 볼 수 있다.



![convarch](https://user-images.githubusercontent.com/77332628/197730869-1bcf21de-dbc9-42e9-8b4f-22d93a5a9550.png)



모델의 계층 구조가 깊으면 특성 재사용과 이로 인한 추상화를 장려하기 때문에 본질적으로 좋다. 일반적으로 작은 층을 깊게 쌓은 모델이 큰 층을 얇게 쌓은 모델보다 성능이 좋다. 하지만 **그레디언트 소실** 문제 때문에 층을 깊게 쌓을 수 있는데에 한계가 있다. 이런 문제를 해결하기 위해 첫번째 핵심 아키텍처 패턴인 잔차 연결이 탄생했다.



### 5.2 잔차 연결



#### 5.2.1 그레디언트 손실

다음과 같이 연결된 함수가 있다고 하자.





*   y = f4(f3(f2(f1(x))))

f4의 출력에 기록된 오차(모델의 손실)를 기반으로 연결된 각 함수의 파라미터를 조정한다고 하자. f1를 조정하려면 f2,f3,f4에 오차 정보를 통과시켜야한다. 하지만 연속적으로 놓은 각 함수에는 일정량의 잡음이 있다. 함수 연결이 너무 깊어지면 각 함수의 잡음들이 그레디언트 정보를 압도하기 시작하고 역전파가 동작하지 않게 된다. 즉, 모델이 전혀 훈련되지 않게 된다. 이를 그레디어트 **손실(vanishing gradient)**이라고 한다.



#### 5.2.2 잔차연결



그레디언트 손실의 해결 방법은 간단하다. 연결된 각 함수들을 이전 입력에 담긴 잡음 없는 정보를 유지시키게 만들면 된다. 이를 구현하는 가장 간단한 방법이 **잔차 연결(residual connection)**이다. 아래 이미지처럼 잔차 연결은 층이나 블록의 입력을 출력에 더하기만 하면 된다.



![conarch2](https://user-images.githubusercontent.com/77332628/197730865-d433dfe1-e469-41e1-8a13-8076ae99fe11.png)



잔차 연결은 잡음이 있는 블록(예를 들어 relu 활성화 함수나 드롭아웃 층을 가진 블록)을 돌아가는 정보의 지름길과 같다. 이전 층의 오차 그레디언트 정보가 잡음없이 네트워크 깊숙히 전파되게 만든다. 이 기법은 **ResNet 모델**과 함께 소개되었다.



잔차 연결은 다음 코드와 같이 구현할 수 있다.



```python
x = ...        # 입력 텐서
residual = x   # 원본 입력을 별도로 저장한다. 이를 잔차라고 부른다.
x = block(x)   # 이 계산은 파괴적(잡음이 있다)일 수도 있다.
x = add([x,residual]) # 원본 입력을 층의 출력에 더한다. 따라서 최종 출력은 항상 원본 입력의 전체 정보를 보존한다.
```

입력을 블록의 출력에 다시 더하는 것은 출력크기가 입력과 같아햐 한다는 것을 의미하지만, 블록에 필터 개수가 늘어난 합성곱 층이나 최대 풀링 층이 들어있는 경우에는 그렇지 않다. 이런 경우에는 다음 코드와 같이 활성화 함수가 없는**1x1 크기의 Conv2D 층**을 사용해서 잔차를 원하는 출력 크기로 선형적으로 투영할 수 있다. 블록에 있는 합성곱 층은 패딩 때문에 공간 방향으로 다운샘플링되지 않도록 일반적으로 padding='same'을 사용한다. 



```python
from tensorflow import keras
from tensorflow.keras import layers

inputs = keras.Input(shape=(32,32,3))
x = layers.Conv2D(32,3,activation='relu')(inputs)
residual = x  # 잔차 별도 저장
x = layers.Conv2D(64,3,activation='relu',padding='same')(x)  
# 잔차 블록에 해당하는 층 , 이 층은 출력 필터를 32개에서 64개로 증가시키고 , 패딩으로 인한 다운샘플링 피하기 위해 padding='same'으로 한다.
residual = layers.Conv2D(64,1)(residual)  # 잔차는 32개의 필터만 있으므로 1x1 Conv2D를 사용해서 적절한 크기로 변환
x = layers.add([x,residual]) # 블록 출려과 잔차의 크기가 같으므로 더할 수 있다.
```

또는 다음 코드처럼 최대 풀링층으로 인한 다운샘플링에 맞추기 위해 잔차 투영에 **스트라이드**를 사용할 수 있다.



```python
inputs = keras.Input(shape=(32,32,3))
x = layers.Conv2D(32,3,activation='relu')(inputs)
residual = x  # 잔차 별도 저장
x = layers.Conv2D(64,3,activation='relu',padding='same')(x)  
x = layers.MaxPooling2D(2,padding='same')(x) # 이 잔차 블록은 최대풀링층을 포함해서 2개의 층으로 구성
residual = layers.Conv2D(64,1,strides=2)(residual) # 최대 풀링층으로 인한 다운샘플링에 맞추기 위해 잔차 투영에 strides=2 사용
x = layers.add([x,residual]) # 블록 출려과 잔차의 크기가 같으므로 더할 수 있다.
```

다음 코드는 좀 더 구체적으로 여러개의 블록으로 구성된 간단한 컨브넷의 예시이다. 각 블록은 2개의 합성곱 층과 하나의 선택적인 최대 풀링층으로 이루어져 있고, 각 블록마다 잔차연결을 가진다. 



```python
from tensorflow import keras
from tensorflow.keras import layers

inputs = keras.Input(shape=(32, 32, 3))
x = layers.Rescaling(1./255)(inputs)

def residual_block(x, filters, pooling=False):  # 잔차연결을 가진 합성곱 블록을 적용하는 유틸리티 함수, 선택저으로 최대 풀링층 추가
    residual = x
    x = layers.Conv2D(filters, 3, activation="relu", padding="same")(x)
    x = layers.Conv2D(filters, 3, activation="relu", padding="same")(x)
    if pooling:
        x = layers.MaxPooling2D(2, padding="same")(x)
        residual = layers.Conv2D(filters, 1, strides=2)(residual)  # 최대 풀링을 사용하면 잔차를 원하는 크기로 투영위해 스트라이드 추가
    elif filters != residual.shape[-1]:
        residual = layers.Conv2D(filters, 1)(residual) # 최대 풀링 사용하지 않으면 채널 수가 바뀐 경우에만 투영
    x = layers.add([x, residual])
    return x

x = residual_block(x, filters=32, pooling=True) # 첫번째 블록
x = residual_block(x, filters=64, pooling=True) # 두번째 블록, 블록마다 필터 개수 증가
x = residual_block(x, filters=128, pooling=False) # 마지막 블록은 다음에 전역 평균 풀링을 사용하기 때문에 풀링 필요X

x = layers.GlobalAveragePooling2D()(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs=inputs, outputs=outputs)
model.summary()
```

```
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               
                                                                                                  
 rescaling (Rescaling)          (None, 32, 32, 3)    0           ['input_1[0][0]']                
                                                                                                  
 conv2d (Conv2D)                (None, 32, 32, 32)   896         ['rescaling[0][0]']              
                                                                                                  
 conv2d_1 (Conv2D)              (None, 32, 32, 32)   9248        ['conv2d[0][0]']                 
                                                                                                  
 max_pooling2d (MaxPooling2D)   (None, 16, 16, 32)   0           ['conv2d_1[0][0]']               
                                                                                                  
 conv2d_2 (Conv2D)              (None, 16, 16, 32)   128         ['rescaling[0][0]']              
                                                                                                  
 add (Add)                      (None, 16, 16, 32)   0           ['max_pooling2d[0][0]',          
                                                                  'conv2d_2[0][0]']               
                                                                                                  
 conv2d_3 (Conv2D)              (None, 16, 16, 64)   18496       ['add[0][0]']                    
                                                                                                  
 conv2d_4 (Conv2D)              (None, 16, 16, 64)   36928       ['conv2d_3[0][0]']               
                                                                                                  
 max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 64)    0           ['conv2d_4[0][0]']               
                                                                                                  
 conv2d_5 (Conv2D)              (None, 8, 8, 64)     2112        ['add[0][0]']                    
                                                                                                  
 add_1 (Add)                    (None, 8, 8, 64)     0           ['max_pooling2d_1[0][0]',        
                                                                  'conv2d_5[0][0]']               
                                                                                                  
 conv2d_6 (Conv2D)              (None, 8, 8, 128)    73856       ['add_1[0][0]']                  
                                                                                                  
 conv2d_7 (Conv2D)              (None, 8, 8, 128)    147584      ['conv2d_6[0][0]']               
                                                                                                  
 conv2d_8 (Conv2D)              (None, 8, 8, 128)    8320        ['add_1[0][0]']                  
                                                                                                  
 add_2 (Add)                    (None, 8, 8, 128)    0           ['conv2d_7[0][0]',               
                                                                  'conv2d_8[0][0]']               
                                                                                                  
 global_average_pooling2d (Glob  (None, 128)         0           ['add_2[0][0]']                  
 alAveragePooling2D)                                                                              
                                                                                                  
 dense (Dense)                  (None, 1)            129         ['global_average_pooling2d[0][0]'
                                                                 ]                                
                                                                                                  
==================================================================================================
Total params: 297,697
Trainable params: 297,697
Non-trainable params: 0
__________________________________________________________________________________________________
```
위의 summary를 보면 잔차 연결을 사용하면 그레디언트 소실에 대해 걱정하지 않고 워하는 깊이의 네트워크를 만들수 있다는 사실을 알 수 있다.



### 5.3 배치 정규화

**정규화**는 머신 러닝 모델에 주입되는 샘플들을 균일하게 만드는 광범위한 개념의 방법이다. 정규화는 모델이 학습하고 새로운 데이터에 잘 일반화되도록 도움을 준다. 이전 글들에서는 데이터가 정규분포 (가우스 분포)를 따른다고 가정하고 아 분포를 워점에 맞추고 분산이 1이 되도록 조정했었다. (다음 코드 참고)



```python
normalized_data = (data - np.mean(data, axis=)) / np.std(data,axis=1)
```

이전 글들의 예제들에서는 모델에 데이터를 주입하기 전에 정규화했었다. 하지만 데이터 정규화는 네트워크에서 일어나는 모든 변환 이후에 필요할 수도 있다. Dense나 Conv2D 층에 들어가는 데이터의 평균이 0이고 분산이 1이더라도 출력되는 데이터가 동일한 분포를 가질 것이라고 기대하기는 어렵다. 따라서 **배치 정규화(Batch Normalization)**을 사용해서 활성화 함수의 출력을 정규화하는 방법이 개발되었다. 배치 정규화는 훈련하는 동안 평균과 분산이 바뀌더라도 이에 적응해서 데이터를 정규화한다. 



배치 정규화의 주요 효과는 잔차 연결과 비슷하게 그레디언트의 전파를 도와주는 것이다. 결국 더 깊은 네트워크 구성에 도움을 준다. 예를 들어 ResNet50, EfficientNet, Xception 등의 케라스에 포함된 고급 컨브넷 구조는 배치 정규화를 많이 사용한다. BatchNormalization 층은 Dense,Conv2D 등을 포함해서 어떤 층 다음에도 사용할 수 있다. 하지만 중요한 점은 일반적으로 활성화 층 이전에 배치 정규화 층을 놓는 것이 좋다. 따라서 다음 코드와 같이 하는 것 보다는,



```python
x = layers.Conv2D(32,3,activation='relu')(x)
x = layers.BatchNormalization(x)
```

다음과 같이 층을 쌓는 것이 효과적이다.



```python
x = layers.Con2D(32,3,use_bias = False) #활성화 함수 지정 X
x = layers.BatchNormalization()(x)
x = layers.Activation('relu')(x) # 배치 정규화 층 다음에 활성화 층을 놓는다.
```

직관적으로 봤을 때 이렇게 하는 이유는 배치 정규화가 입력 평균을 0으로 만들지만, relu 활성화 함수는 0을 기준으로 값을 통과시키거나 삭제 시키기 때문이다. 활성화 함수 이전에 정규화를 수행하면 relu 함수의 활용도가 극대화 된다. 


### 5.4 깊이별 분리 합성곱

Conv2D를 대체하면서 더 작고(=훈련할 모델 파라미터가 더 적고) , 더 가볍고(= 연산이 더 적고) 모델의 성능을 조금이라도 높일 수 있는 층이 있다. 이는 **깊이별 분리 합성곱**층이 하는 일이다. 이 층은 입력 채널별로 따로따로 공간 방향의 합성곱을 수행한 후, 아래 이미지와 같이 점별 합성곱(1x1) 합성곱을 통해 출력 채널을 합치는 역할을 한다. (케라스에서는 SeparableConv2D에 구현되어 있다.)



![convarch3](https://user-images.githubusercontent.com/77332628/197730875-4c5873f3-5ce5-47c0-9ebb-2a157d136369.png)



이는 공간 특성의 학습과 채널 방향 특성의 학습을 분리하는 효과를 낸다. 깊이별 분리 합성곱은 일반 합성곱보다 훨씩 적은 개수의 파라미터를 사용하고 더 적은 수의 연산을 수행하면서 유사한 표현 능력을 가지고 있다. 그렇기 때문에 수렴이 더 빠르고 쉽게 과대적합되지 않는 작은 모델을 만든다. 이런 장점은 제한된 데이터로 밑바닥부터 작은 모델을 훈련할 때 특히 중요하다. 



### 5.5 Xception 유사 모델에 모두 적용하기

이 글에서 배운 컨브넷 아키텍처 원칙들을 다음과 같이 정리할 수 있다.





* 모델은 반복되는 층 **블록**으로 조직되어야 한다. 블록은 일반적으로 여러개의 합성곱 층과 최대 풀링 층으로 구성된다.

* 특성 맵의 공간 방향 크기가 줄어듦에 따라 층의 필터 개수는 증가해야한다.

* 깊고 좁은 아키텍처가 넓고 얇은 것보다 낫다.

* 층 블록에 **잔차 연결**을 추가하면 깊은 네트워크를 훈련하는데 효과적이다.

* 합성곱 층 다음에 **배치 정규화 층**을 추가하면 도움이 될 수 있다.

* Conv2D 층을 더 가벼운 **SeparableConv2D층**으로 바꾸면 도움이 될 수 있다.



이런 아이디어들을 하나의 모델에 적용해 보겠다. 밑에 만들 모델은 작은 버전의 Xception 모델과 비슷한데, 이 모델을 *강아지vs고양이* 데이터셋에 적용한다.




```python
import gdown
gdown.download(id='18uC7WTuEXKJDDxbj-Jq6EjzpFrgE7IAd', output='dogs-vs-cats.zip')  # 데이터 내려받는 코드
!unzip -qq dogs-vs-cats.zip
!unzip -qq train.zip
```

```
Downloading...
From: https://drive.google.com/uc?id=18uC7WTuEXKJDDxbj-Jq6EjzpFrgE7IAd
To: /content/dogs-vs-cats.zip
100%|██████████| 852M/852M [00:13<00:00, 63.2MB/s]
```

```python
from tensorflow import keras
from tensorflow.keras import layers
import os, shutil, pathlib
from tensorflow.keras.utils import image_dataset_from_directory

# 내려받은 데이터 파일 만들기
original_dir = pathlib.Path("train")
new_base_dir = pathlib.Path("cats_vs_dogs_small")

def make_subset(subset_name, start_index, end_index):
    for category in ("cat", "dog"):
        dir = new_base_dir / subset_name / category
        os.makedirs(dir)
        fnames = [f"{category}.{i}.jpg" for i in range(start_index, end_index)]
        for fname in fnames:
            shutil.copyfile(src=original_dir / fname,
                            dst=dir / fname)

make_subset("train", start_index=0, end_index=1000)
make_subset("validation", start_index=1000, end_index=1500)
make_subset("test", start_index=1500, end_index=2500)

train_dataset = image_dataset_from_directory(
    new_base_dir / "train",
    image_size=(180, 180),
    batch_size=32)
validation_dataset = image_dataset_from_directory(
    new_base_dir / "validation",
    image_size=(180, 180),
    batch_size=32)
test_dataset = image_dataset_from_directory(
    new_base_dir / "test",
    image_size=(180, 180),
    batch_size=32)
```

```
Found 2000 files belonging to 2 classes.
Found 1000 files belonging to 2 classes.
Found 2000 files belonging to 2 classes.
```

```python
data_augmentation = keras.Sequential(    # 데이터 증식
    [
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.2),])
```


```python
inputs = keras.Input(shape=(180,180,3))
x = data_augmentation(inputs)
x = layers.Rescaling(1./255)(x)
x = layers.Conv2D(filters=32,kernel_size=5,use_bias=False)(x)

for size in [32,64,128,256,512]: 
 ''' 특성 맵 깊이를 증가시키면서 합성곱 블록을 연속적으로 적용한다.
 각 블록은 배치정규화를 적용한 2개의 깊이별 분리 합성곱 층과 하나의 최대 풀링층으로 구성되고,
 블록마다 잔차 연결이 추가된다.''' 
 residual = x # 잔차는 별도로 저장 
 
 x = layers.BatchNormalization()(x) # 배치 정규화
 x = layers.Activation('relu')(x)
 x = layers.SeparableConv2D(size,3,padding='same',use_bias=False)(x) # 깊이별 분리 합성곱
  
 x = layers.BatchNormalization()(x) 
 x = layers.Activation('relu')(x)
 x = layers.SeparableConv2D(size,3,padding='same',use_bias=False)(x)

 x = layers.MaxPooling2D(3,strides=2,padding='same')(x)

 residual = layers.Conv2D(
     size,1,strides=2,padding='same',use_bias=False)(residual) 
 x = layers.add([x,residual]) # 잔차 연결

x = layers.GlobalAveragePooling2D()(x) # Dense 층 이전에 Flatten 대신 GlobalAveragePooling2D 사용
x = layers.Dropout(0.5)(x) # 규제를 위해 드롭아웃 층 사용
outputs = layers.Dense(1,activation='sigmoid')(x)
model = keras.Model(inputs=inputs,outputs= outputs)

model.summary()
```

```
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 180, 180, 3  0           []                               
                                )]                                                                
                                                                                                  
 sequential (Sequential)        (None, 180, 180, 3)  0           ['input_1[0][0]']                
                                                                                                  
 rescaling (Rescaling)          (None, 180, 180, 3)  0           ['sequential[0][0]']             
                                                                                                  
 conv2d (Conv2D)                (None, 176, 176, 32  2400        ['rescaling[0][0]']              
                                )                                                                 
                                                                                                  
 batch_normalization (BatchNorm  (None, 176, 176, 32  128        ['conv2d[0][0]']                 
 alization)                     )                                                                 
                                                                                                  
 activation (Activation)        (None, 176, 176, 32  0           ['batch_normalization[0][0]']    
                                )                                                                 
                                                                                                  
 separable_conv2d (SeparableCon  (None, 176, 176, 32  1312       ['activation[0][0]']             
 v2D)                           )                                                                 
                                                                                                  
 batch_normalization_1 (BatchNo  (None, 176, 176, 32  128        ['separable_conv2d[0][0]']       
 rmalization)                   )                                                                 
                                                                                                  
 activation_1 (Activation)      (None, 176, 176, 32  0           ['batch_normalization_1[0][0]']  
                                )                                                                 
                                                                                                  
 separable_conv2d_1 (SeparableC  (None, 176, 176, 32  1312       ['activation_1[0][0]']           
 onv2D)                         )                                                                 
                                                                                                  
 max_pooling2d (MaxPooling2D)   (None, 88, 88, 32)   0           ['separable_conv2d_1[0][0]']     
                                                                                                  
 conv2d_1 (Conv2D)              (None, 88, 88, 32)   1024        ['conv2d[0][0]']                 
                                                                                                  
 add (Add)                      (None, 88, 88, 32)   0           ['max_pooling2d[0][0]',          
                                                                  'conv2d_1[0][0]']               
                                                                                                  
 batch_normalization_2 (BatchNo  (None, 88, 88, 32)  128         ['add[0][0]']                    
 rmalization)                                                                                     
                                                                                                  
 activation_2 (Activation)      (None, 88, 88, 32)   0           ['batch_normalization_2[0][0]']  
                                                                                                  
 separable_conv2d_2 (SeparableC  (None, 88, 88, 64)  2336        ['activation_2[0][0]']           
 onv2D)                                                                                           
                                                                                                  
 batch_normalization_3 (BatchNo  (None, 88, 88, 64)  256         ['separable_conv2d_2[0][0]']     
 rmalization)                                                                                     
                                                                                                  
 activation_3 (Activation)      (None, 88, 88, 64)   0           ['batch_normalization_3[0][0]']  
                                                                                                  
 separable_conv2d_3 (SeparableC  (None, 88, 88, 64)  4672        ['activation_3[0][0]']           
 onv2D)                                                                                           
                                                                                                  
 max_pooling2d_1 (MaxPooling2D)  (None, 44, 44, 64)  0           ['separable_conv2d_3[0][0]']     
                                                                                                  
 conv2d_2 (Conv2D)              (None, 44, 44, 64)   2048        ['add[0][0]']                    
                                                                                                  
 add_1 (Add)                    (None, 44, 44, 64)   0           ['max_pooling2d_1[0][0]',        
                                                                  'conv2d_2[0][0]']               
                                                                                                  
 batch_normalization_4 (BatchNo  (None, 44, 44, 64)  256         ['add_1[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 activation_4 (Activation)      (None, 44, 44, 64)   0           ['batch_normalization_4[0][0]']  
                                                                                                  
 separable_conv2d_4 (SeparableC  (None, 44, 44, 128)  8768       ['activation_4[0][0]']           
 onv2D)                                                                                           
                                                                                                  
 batch_normalization_5 (BatchNo  (None, 44, 44, 128)  512        ['separable_conv2d_4[0][0]']     
 rmalization)                                                                                     
                                                                                                  
 activation_5 (Activation)      (None, 44, 44, 128)  0           ['batch_normalization_5[0][0]']  
                                                                                                  
 separable_conv2d_5 (SeparableC  (None, 44, 44, 128)  17536      ['activation_5[0][0]']           
 onv2D)                                                                                           
                                                                                                  
 max_pooling2d_2 (MaxPooling2D)  (None, 22, 22, 128)  0          ['separable_conv2d_5[0][0]']     
                                                                                                  
 conv2d_3 (Conv2D)              (None, 22, 22, 128)  8192        ['add_1[0][0]']                  
                                                                                                  
 add_2 (Add)                    (None, 22, 22, 128)  0           ['max_pooling2d_2[0][0]',        
                                                                  'conv2d_3[0][0]']               
                                                                                                  
 batch_normalization_6 (BatchNo  (None, 22, 22, 128)  512        ['add_2[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 activation_6 (Activation)      (None, 22, 22, 128)  0           ['batch_normalization_6[0][0]']  
                                                                                                  
 separable_conv2d_6 (SeparableC  (None, 22, 22, 256)  33920      ['activation_6[0][0]']           
 onv2D)                                                                                           
                                                                                                  
 batch_normalization_7 (BatchNo  (None, 22, 22, 256)  1024       ['separable_conv2d_6[0][0]']     
 rmalization)                                                                                     
                                                                                                  
 activation_7 (Activation)      (None, 22, 22, 256)  0           ['batch_normalization_7[0][0]']  
                                                                                                  
 separable_conv2d_7 (SeparableC  (None, 22, 22, 256)  67840      ['activation_7[0][0]']           
 onv2D)                                                                                           
                                                                                                  
 max_pooling2d_3 (MaxPooling2D)  (None, 11, 11, 256)  0          ['separable_conv2d_7[0][0]']     
                                                                                                  
 conv2d_4 (Conv2D)              (None, 11, 11, 256)  32768       ['add_2[0][0]']                  
                                                                                                  
 add_3 (Add)                    (None, 11, 11, 256)  0           ['max_pooling2d_3[0][0]',        
                                                                  'conv2d_4[0][0]']               
                                                                                                  
 batch_normalization_8 (BatchNo  (None, 11, 11, 256)  1024       ['add_3[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 activation_8 (Activation)      (None, 11, 11, 256)  0           ['batch_normalization_8[0][0]']  
                                                                                                  
 separable_conv2d_8 (SeparableC  (None, 11, 11, 512)  133376     ['activation_8[0][0]']           
 onv2D)                                                                                           
                                                                                                  
 batch_normalization_9 (BatchNo  (None, 11, 11, 512)  2048       ['separable_conv2d_8[0][0]']     
 rmalization)                                                                                     
                                                                                                  
 activation_9 (Activation)      (None, 11, 11, 512)  0           ['batch_normalization_9[0][0]']  
                                                                                                  
 separable_conv2d_9 (SeparableC  (None, 11, 11, 512)  266752     ['activation_9[0][0]']           
 onv2D)                                                                                           
                                                                                                  
 max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 512)   0           ['separable_conv2d_9[0][0]']     
                                                                                                  
 conv2d_5 (Conv2D)              (None, 6, 6, 512)    131072      ['add_3[0][0]']                  
                                                                                                  
 add_4 (Add)                    (None, 6, 6, 512)    0           ['max_pooling2d_4[0][0]',        
                                                                  'conv2d_5[0][0]']               
                                                                                                  
 global_average_pooling2d (Glob  (None, 512)         0           ['add_4[0][0]']                  
 alAveragePooling2D)                                                                              
                                                                                                  
 dropout (Dropout)              (None, 512)          0           ['global_average_pooling2d[0][0]'
                                                                 ]                                
                                                                                                  
 dense (Dense)                  (None, 1)            513         ['dropout[0][0]']                
                                                                                                  
==================================================================================================
Total params: 721,857
Trainable params: 718,849
Non-trainable params: 3,008
__________________________________________________________________________________________________
```
위의 모델의 훈련 가능한 파라미터 개수는 721,857개로 원본 모델의 파라미터 개수인 99만여개 보다 조금 적다. 훈련 결과는 어떻게 다른지 알아보자.



```python
callbacks = [ 
    keras.callbacks.ModelCheckpoint(           # 콜백 사용
        filepath="convnet_best_architecture.keras", # 모델 저장 경로
        save_best_only=True,                   # val_loss 값이 이전보다 낮을 때만 저장
        monitor="val_loss")
]
model.compile(loss="binary_crossentropy",
              optimizer="rmsprop",
              metrics=["accuracy"])
history = model.fit(
    train_dataset,
    epochs=100,
    validation_data=validation_dataset,
    callbacks=callbacks)
```

```
Epoch 1/100
63/63 [==============================] - 44s 476ms/step - loss: 0.0994 - accuracy: 0.9640 - val_loss: 0.5640 - val_accuracy: 0.8870
Epoch 2/100
63/63 [==============================] - 30s 467ms/step - loss: 0.0808 - accuracy: 0.9705 - val_loss: 0.3714 - val_accuracy: 0.9010
.
.
.
Epoch 99/100
63/63 [==============================] - 30s 470ms/step - loss: 0.0439 - accuracy: 0.9865 - val_loss: 0.7075 - val_accuracy: 0.8810
Epoch 100/100
63/63 [==============================] - 29s 451ms/step - loss: 0.0532 - accuracy: 0.9805 - val_loss: 0.4746 - val_accuracy: 0.8960
```

```python
import matplotlib.pyplot as plt
accuracy = history.history["accuracy"]
val_accuracy = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(accuracy) + 1)
plt.plot(epochs, accuracy, "bo", label="Training accuracy")
plt.plot(epochs, val_accuracy, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()
```

![convarch4](https://user-images.githubusercontent.com/77332628/197730876-d0b07b9a-50b5-4c12-ace5-636832c9da69.png)
![convarch5](https://user-images.githubusercontent.com/77332628/197730878-236bd7d0-1870-4e72-afc9-8e71b4fd8675.png)

```python
test_model = keras.models.load_model("convnet_best_architecture.keras")
test_loss, test_acc = test_model.evaluate(test_dataset)
print(f"테스트 정확도: {test_acc:.3f}")
```

<pre>
63/63 [==============================] - 3s 42ms/step - loss: 0.3586 - accuracy: 0.8835
테스트 정확도: 0.883
</pre>
위의 그래프를 보면 [이전 글](https://hamin-chang.github.io/small/) 에서 구축한 

단순한 모델보다 파라미터 수가 적지만 원본 모델과 여전히 동일한 성능 범위 안에 있다. 이번 글에서 만든 새로운 모델은 88.3%의 테스트 정확도를 보이지만 이전 글의 단순한 모델은 69% 정도의 테스트 정확도를 달성했었다. 테스트 정확도를 비교하면 알 수 있듯이 아키텍처 모범 사례를 따르면 모델 성능에 즉각적이고 괄목할 만한 영향을 줄 수 있다. 



(이 시점에서 성능을 더 향상시키려면 모델의 파라미터를 체계적으로 튜닝해야한다. 이 주제는 다른 글에서 다루겠다.)



이것으로 핵심적인 컨브넷 아키텍처 모범 사례에 대한 글을 마치겠다.

[<케라스 창시자에게 배우는 딥러닝 개정 2판>(길벗, 2022)을 학습하고 개인 학습용으로 정리한 내용입니다.] 출처: 프랑소와 숄레 지음, ⌜케라스 창시자에게 배우는 딥러닝 개정2판⌟, 박해선 옮김, 길벗, 2022 도서보기: https://www.gilbut.co.kr/book/view?bookcode=BN003496

