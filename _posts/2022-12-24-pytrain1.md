---
title : '[DL/Pytorch] νμ΄ν† μΉλ΅ ν•™μµν•κΈ°1 - νλΌλ―Έν„° μµμ ν™” π΅οΈ'
layout: single
toc: true
toc_sticky: true
categories:
  - pytorchBasic
---

## νμ΄ν† μΉ λ¨λΈμ΄ ν•™μµν•λ” κ³Όμ •\(νλΌλ―Έν„° μµμ ν™”\)

μ΄λ² κΈ€μ—μ„λ” νμ΄ν† μΉ λ¨λΈμ΄ ν•™μµμ„ ν•λ” κ³Όμ •μ— λ€ν•΄μ„ λ‹¤λ£¬λ‹¤. κ°„λ‹¨ν• μμ λ¥Ό ν’€μ–΄κ°€λ©΄μ„ νμ΄ν† μΉ λ¨λΈμ΄ μ–΄λ–¤ κ³Όμ •μ„ ν†µν•΄ ν•™μµμ„ ν•λ”μ§€ μ•μ•„λ³΄μ.

### 1. μ¨λ„λ¬Έμ 

μλ¥Ό λ“¤μ–΄λ³΄μ. μ°λ¦¬κ°€ μ–΄λ””λ΅ μ—¬ν–‰μ„ κ°€μ„ κ·Έκ³³μ κΈ°μ¨μ„ μ•μ•„λ³΄κΈ° μ„ν•΄ μ¨λ„κ³„λ¥Ό ν™•μΈν•΄λ΄¤λ”λ° κ·Έ μ¨λ„κ³„λ” λ‹¨μ„κ°€ μ ν€μμ§€ μ•μ€ μ¨λ„κ³„μ—¬μ„ μ •ν™•ν• μ¨λ„λ¥Ό μ•μ§€ λ»ν•λ‹¤. μ΄ μ¨λ„ λ¬Έμ λ¥Ό κ°„λ‹¨ν• νμ΄ν† μΉ λ¨λΈμ„ λ§λ“¤μ–΄μ„ ν’€μ–΄λ³΄μ. μ°λ¦¬κ°€ μΈ΅μ •ν• λ‹¨μ„λ¥Ό λ¨λ¥΄λ” μ¨λ„μ— λ€μ‘ν•λ” μ„­μ”¨ μ¨λ„λ¥Ό μ–»μ–΄μ™”λ‹¤.




```python
import torch
t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0] # μ„­μ”¨ μ¨λ„
t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4] # λ―Έμ§€μ μ¨λ„
t_c = torch.tensor(t_c) # λ¦¬μ¤νΈλ¥Ό ν…μ„λ΅ λ³€ν™
t_u = torch.tensor(t_u)
```

t_c μ™€ t_uκ°€ μ„ ν•μ μΈ κ΄€κ³„λ¥Ό κ°€μ§„λ‹¤κ³  κ°€μ •ν•κ³  μ„ ν• λ¨λΈμ„ μ„ νƒν•΄μ„ λ¬Έμ λ¥Ό ν’€μ–΄λ³΄μ. μ¦‰, t_uμ— μ–΄λ–¤ κ°’μ„ κ³±ν•κ³  μƒμλ¥Ό λ”ν•λ©΄ t_cλ¥Ό μ–»μ„ μ μλ‹¤κ³  κ°€μ •ν•κ³  μ„ ν• λ¨λΈμ„ μ„ νƒν•λ‹¤. 

t_c = t_u * w + b (w=κ°€μ¤‘μΉ, b=νΈν–¥κ°’)

μ΄μ  w,bλ” μ°λ¦¬ μ„ ν• λ¨λΈμ νλΌλ―Έν„°μ΄λ‹¤. λ”°λΌμ„ λ¨λΈμ΄ μΌλ ¨μ κ³„μ‚° κ³Όμ •μ„ κ±°μ³κ°€λ©° μµμ μ νλΌλ―Έν„°λ¥Ό μ°Ύμ•„κ°€λ” κ³Όμ •μ„ 'ν•™μµ'μ΄λΌκ³  λ³Ό μ μλ‹¤. μ—¬κΈ°μ„ μµμ μ νλΌλ―Έν„°λ€ μΈ΅μ •λ κ°’(t_c)μ™€ μμΈ΅κ°’ μ‚¬μ΄μ μ¤μ°¨λ¥Ό μµλ€ν• μ‘κ² λ§λ“λ” νλΌλ―Έν„°λ¥Ό μΉ­ν•λ‹¤. 

#### 1.1 μ†μ‹¤μ„ μ¤„μ΄λ” λ°©λ²•

**μ†μ‹¤ ν•¨μ**λ” ν•™μµ κ³Όμ •μ„ ν†µν•΄ μµμ†ν™”ν•κ³ μ ν•λ” κ°’μ„ κ³„μ‚°ν•λ” ν•¨μλ‹¤. μ†μ‹¤ ν•¨μλ” μΌλ°μ μΌλ΅ ν›λ ¨ μƒν”λ΅λ¶€ν„°μ μ¶λ ¥κ°’κ³Ό μ‹¤μ  μ •λ‹µκ°’ μ‚¬μ΄μ μ°¨μ΄λ¥Ό κ³„μ‚°ν•λ‹¤(μ¨λ„ λ¬Έμ μ— κ²½μ° t_p - t_c). μ†μ‹¤ν•¨μλ” ν•­μƒ μ–‘μκ°’μ΄ λ‚μ¤κ² ν•΄μ„ t_pκ°€ t_cλ΅ λ§μ¶°κ°€λ” λ° μ‚¬μ©ν•  μ μκ² ν•΄μ•Όν•λ‹¤. μ΄λ¥Ό μ„ν•΄μ„ λ‘ κ°’μ μ°¨μ΄κ°’μ μ λ€κ°’ νΉμ€ μ κ³±κ°’μ„ μ‚¬μ©ν•λ‹¤. κ·ΈλΌ μ λ“κ°’κ³Ό μ κ³±κ°’ κ·Έλν”„ μ¤‘ μ–΄λ–¤ μ†μ‹¤ν•¨μλ¥Ό μ‚¬μ©ν•΄μ•Ό ν• κΉ? μ•„λ κ·Έλ¦Όμ„ λ³΄λ©΄ μ λ“κ°’(νλ‘) κ·Έλν”„λ” μ κ³±κ°’(λΉ¨κ°•) κ·Έλν”„μ™€ λ‹¬λ¦¬ μ°λ¦¬κ°€ μλ ΄ν•κ³ μ ν•λ” κ²½μ°μ— λ―Έλ¶„ κ°’μ„ μ •μν•  μ μ—†κΈ° λ•λ¬Έμ— μ κ³±κ°’ μ†μ‹¤ ν•¨μλ¥Ό μ‚¬μ©ν•λ‹¤. λν• μ κ³±κ°’μ„ μ΄μ©ν• μ†μ‹¤ ν•¨μλ” μ λ“κ°’ μ†μ‹¤ν•¨μλ³΄λ‹¤ μλ»λ κ²°κ³Ό(μ¤μ°¨κ°€ ν° κ²°κ³Ό)μ— λ” λ§μ€ λ¶μ΄μµ(μ¤μ°¨)λ¥Ό μ£ΌκΈ° λ•λ¬Έμ— μ¤μ°¨ λ³΄μ •μ— μ°μ„ μμ„λ¥Ό μ£Όλ„λ΅ λ™μ‘ν•λ‹¤.

[2022-12-24-pytrain1.md](https://github.com/Hamin-Chang/Hamin-Chang.github.io/files/10298157/2022-12-24-pytrain1.md)

### 2. νμ΄ν† μΉλ΅ λ¬Έμ  ν’€μ–΄λ³΄κΈ°
μ΄μ  λ¨λΈμ„ μ„ ν• λ¨λΈμ„ μ„ νƒν–κ³ , μ†μ‹¤ν•¨μλ” μΈ΅μ •κ°’κ³Ό μ •λ‹µκ°’μ μ°¨μ΄λ¥Ό μ κ³±ν• ν…μ„λ¥Ό λ§λ“  ν›„ λ¨λ“  μ”μ†μ— λ€ν• ν‰κ· μ„ κµ¬ν•΄μ„ μ¤μΉΌλΌ κ°’μ„ λ§λ“¤μ–΄λ‚΄λ” **ν‰κ·  μ κ³± μ†μ‹¤(mean squared error)**μ„ μ‚¬μ©ν•λ„λ΅ ν•μ.


```python
def model(t_u,w,b): # μ°¨λ΅€λ€λ΅ μ…λ ¥ν…μ„, κ°€μ¤‘μΉ νλΌλ―Έν„°, νΈν–¥κ°’ νλΌλ―Έν„°
  return w * t_u + b 

def loss_fn(t_p, t_c): # μ°¨λ΅€λ€λ΅ μ¶λ ¥κ°’ , μ •λ‹µκ°’
  squared_diffs = (t_p - t_c)**2
  return squared_diffs.mean()
```

κ°€μ¤‘μΉ νλΌλ―Έν„°λ” 1λ΅, νΈν–¥κ°’ νλΌλ―Έν„°λ” 0μΌλ΅ μ΄κΈ°ν™”ν•κ³  λ¨λΈμ„ μ‘λ™ μ‹μΌμ„ μ¶λ ¥κ°’μ„ μ¶λ ¥ν•΄λ³΄κ³ , μ†μ‹¤κ°’μ„ μ¶λ ¥ν•΄λ³΄μ.


```python
w = torch.ones(())
b = torch.zeros(())

t_p = model(t_u,w,b)
t_p
```




    tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000, 21.8000,
            48.4000, 60.4000, 68.4000])




```python
loss = loss_fn(t_p,t_c)
loss
```




    tensor(1763.8848)



### 3. κ²½μ‚¬ν•κ°•μ„ ν†µν• νλΌλ―Έν„° μµμ ν™”
μ„μ μ½”λ“μ—μ„ μ¶λ ¥ν• μ†μ‹¤κ°’μ€ κµ‰μ¥ν ν¬λ‹¤! μ΄μ  λ³Έκ²©μ μΈ νλΌλ―Έν„° μµμ ν™”λ¥Ό   **κ²½μ‚¬ ν•κ°• μ•κ³ λ¦¬μ¦**μ„ μ‚¬μ©ν•΄μ„ μ§„ν–‰ν•΄λ³΄μ. κ²½μ‚¬ν•κ°•μ€ κ° νλΌλ―Έν„°μ™€ κ΄€λ ¨ν•΄μ„ μ†μ‹¤μ λ³€ν™”μ¨μ„ κ³„μ‚°ν•΄μ„ μ†μ‹¤μ΄ μ¤„μ–΄λ“λ” λ°©ν–¥μΌλ΅ νλΌλ―Έν„° κ°’μ„ λ°”κΏ”λ‚κ°€λ” κΈ°λ²•μ΄λ‹¤. 


```python
delta = 0.1 # wμ™€ bκ°€ λ³€ν•λ” μ •λ„

loss_rate_of_change_w = (loss_fn(model(t_u,w+delta,b),t_c) - loss_fn(model(t_u,w-delta,b),t_c)) / (2.0 * delta) 

loss_rate_of_change_b = (loss_fn(model(t_u,w,b+delta),t_c) - loss_fn(model(t_u,w,b-delta),t_c)) / (2.0 * delta) 
```

μ„μ μ½”λ“λ” wμ™€ bκ°’μ—μ„ νΉμ • λ‹¨μ„λ§νΌ wμ™€ bκ°€ μ¦κ°€ν–μ„ λ•μ μ†μ‹¤μ΄ λ³€ν•κ² λ§λ“ λ‹¤. μ†μ‹¤κ°’μ΄ μ¤„μ–΄λ“¤λ©΄ wλ¥Ό λ” λλ¦¬κ³ , μ†μ‹¤κ°’μ΄ λμ–΄λ‚λ©΄ λ°λ€λ΅ wλ¥Ό μ¤„μ—¬μ„ μ†μ‹¤μ„ μµμ†ν™”ν•λ” μ‹μ΄λ‹¤. κ·Έλ ‡λ‹¤λ©΄ wλ¥Ό μ–Όλ§λ‚ λλ¦¬κ±°λ‚ μ¤„μ΄λ©΄ μΆ‹μ„κΉ? λ³΄ν†µ μ†μ‹¤μ λ³€ν™” λΉ„μ¨μ— λΉ„λ΅€ν•΄μ„ wλ¥Ό λ°”κΎΈλ” λ°©λ²•μ„ λ§μ΄ μ‚¬μ©ν•λ‹¤. μ–Όλ§λ§νΌ λ°”κΏ”κ° κ²ƒμΈμ§€μ— λ€ν• μ¤μΌ€μΌλ§ λΉ„μ¨μ„ λ‚νƒ€λ‚΄λ” κ²ƒμ„ λ¨Έμ‹ λ¬λ‹μ—μ„λ” μ£Όλ΅ learning_rateλΌλ” λ³€μλ…μ„ μ‚¬μ©ν•λ‹¤.


```python
learning_rate = 1e-2

w = w - learning_rate * loss_rate_of_change_w
b = b - learning_rate * loss_rate_of_change_b
```

μ„μ μ½”λ“μ—μ„λ” delta κ°’μ„ 0.1λ΅ λ‘μ—λ”λ°, μ΄λ” wμ™€ bμ— λ€ν• μ†μ‹¤ν•¨μμ λ¨μ–‘μ— λ”°λΌ λ‹¬λΌμ§€κΈ° λ€λ¬Έμ— μΈμ ‘ μμ—­μ„ μ–Όλ§μ κ±°λ¦¬κΉμ§€λ΅ λ³Ό κ²ƒμΈμ§€ κ·μ •ν•κΈ°κ°€ μ–΄λ µλ‹¤. μ§€μ •ν• delta κ°’μ— λΉ„ν•΄ μ†μ‹¤κ°’μ΄ λ„λ¬΄ λΉ λ¥΄κ² λ³€ν•λ‹¤λ©΄, μ†μ‹¤κ°’μ„ μµμ†ν™”ν•κΈ° μ„ν•΄ μ–΄λ λ°©ν–¥μΌλ΅ νλΌλ―Έν„°λ¥Ό μ΅°μ •ν• μ§€μ— λ€ν• νλ‹¨μ„ λ‚΄λ¦¬κΈ°λ” μ‰½μ§€ μ•μ„ κ²ƒμ΄λ‹¤. κ·Έλ ‡λ‹¤λ©΄ μ•„λ μ΄λ―Έμ§€μ²λΌ μΈμ ‘ν• κ±°λ¦¬(delta)λ¥Ό κ·Ήλ‹¨μ μΌλ΅ μ¤„μ—¬λ³΄μ! μ΄λ ‡κ² ν•λ©΄ κ²°κµ­ νλΌλ―Έν„°μ— λ€ν•΄ μ†μ‹¤ ν•¨μλ¥Ό λ―Έλ¶„ν•λ” κ²ƒκ³Ό κ°™λ‹¤. λ‘κ° μ΄μƒμ νλΌλ―Έν„°λ¥Ό κ°€μ§„ λ¨λΈμ—μ„λ” κ° νλΌλ―Έν„°μ— λ€ν• μ†μ‹¤ ν•¨μμ νΈλ―Έλ¶„μ„ κµ¬ν•κ³  μ΄ νΈλ―Έλ¶„ κ°’λ“¤μ„ λ―Έλ¶„ λ²΅ν„°μ— λ„£μΌλ©΄ , μ΄κ²ƒμ΄ λ°”λ΅ **κΈ°μΈκΈ°(gradient)**λ‹¤.

![train2](https://user-images.githubusercontent.com/77332628/209425879-5a06f029-7ac3-4f7b-9be1-a9e90cd9692e.jpg)

μ†μ‹¤ν•¨μλ¥Ό νλΌλ―Έν„°μ— λ€ν•΄ κ³„μ‚°ν•λ ¤λ©΄ μ—°μ‡„ λ²•μΉ™μ„ μ μ©ν•΄μ„ μ†μ‹¤ν•¨μλ¥Ό μ…λ ¥κ°’(λ¨λΈμ μ¶λ ¥κ°’)μ— λ€ν•΄ λ―Έλ¶„ν• κ°’κ³Ό μ…λ ¥(λ¨λΈμ μ¶λ ¥κ°’)μ„ νλΌλ―Έν„°μ— λ€ν•΄ λ―Έλ¶„ν• κ°’μ„ κ³±ν•΄μ„ κ³„μ‚°ν•λ©΄ λλ‹¤.

$dLoss/dw = (dLoss/dt_p) * (dt_p/dw)$

μ΄μ  μ½”λ“λ΅ κµ¬ν„ν•΄λ³΄μ.

μ›λμ μ†μ‹¤ ν•¨μλ” λ‹¤μκ³Ό κ°™μ•λ”λ°,


```python
def loss_fn(t_p, t_c):
  squared_diffs = (t_p - t_c) ** 2
  return squared_diffs.mean()
```

$dx^2 /dx = 2x$λ¥Ό μ΄μ©ν•΄μ„ λ‹¤μκ³Ό κ°™μ΄ μ†μ‹¤ ν•¨μλ¥Ό μ…λ ¥κ°’μ— λ€ν• λ―Έλ¶„ κ°’μ„ κµ¬ν„ν•  μ μλ‹¤.


```python
def dloss_fn(t_p,t_c):
  dsq_diffs = 2*(t_p - t_c) / t_p.size(0) # ν‰κ· μ λ„ν•¨μλ΅ λ‚λ”
  return dsq_diffs
```

μ°λ¦¬μ λ¨λΈμ€ λ‹¤μκ³Ό κ°™μ€λ°,


```python
def model(t_u,w,b): 
  return w * t_u + b 
```

λ‹¤μκ³Ό κ°™μ΄ λ¨λΈμ μ¶λ ¥ κ°’μ„ νλΌλ―Έν„°μ— λ€ν• λ―Έλ¶„κ°’μ„ μ½”λ“λ΅ κµ¬ν„ν•  μ μλ‹¤.


```python
def dmodel_dw(t_u,w,b): # wμ— λ€ν•΄ λ―Έλ¶„
  return t_u

def dmodel_db(t_u,w,b): # bμ— λ€ν•΄ λ―Έλ¶„
  return 1.0
```

μ„μ μ½”λ“λ“¤μ„ μ—°μ‡„λ²•μΉ™μΌλ΅ μ—®μ–΄μ„ μ†μ‹¤κ°’μ„ wμ™€bμ— λ€ν•΄ λ―Έλ¶„ν• κ°’μ„ λ‚νƒ€λ‚΄λ” ν•¨μλ¥Ό λ‹¤μκ³Ό κ°™μ΄ κµ¬ν„ν•  μ μλ‹¤.


```python
def grad_fn(t_u,t_c,t_p,w,b):
  dloss_dtp = dloss_fn(t_p,t_c)
  dloss_dw = dloss_dtp * dmodel_dw(t_u,w,b)
  dloss_db = dloss_dtp * dmodel_db(t_u,w,b)
  return torch.stack([dloss_dw.sum(), dloss_db.sum()])
```

### 4. λ¨λΈ μ ν•©μ„ μ„ν• λ°λ³µ
νλΌλ―Έν„°λ¥Ό μµμ ν™”ν•κΈ° μ„ν• μ¤€λΉ„κ°€ μ™„λ£λμ—μΌλ‹, νλΌλ―Έν„°λ¥Ό μ„μ‹κ°’μ—μ„ μ¶λ°ν•΄μ„ κ³ μ •λ νμ(**μ—ν¬ν¬ epoch**)λ§νΌ λ°λ³µν•΄μ„ νλΌλ―Έν„°κ°€ λ³€ν•μ§€ μ•μ„λ•κΉμ§€ μ΅°μ •ν•λ‹¤. κ° μ—ν¬ν¬λ§λ‹¤ ν›λ ¨(μλ°©ν–¥ μ „λ‹¬, μ†μ‹¤ν•¨μ μ •μ, μ—­λ°©ν–¥ μ „λ‹¬, νλΌλ―Έν„° μ΅°μ •)μ„ ν•λ” ν›λ ¨ λ£¨ν”„λ¥Ό λ§λ“λ” ν•¨μλ¥Ό μ •μν•΄λ³΄μ.


```python
def training_loop(n_epochs,learning_rate, params,t_u,t_c):
  
  for epoch in range(1, n_epochs+1):
    w,b = params

    t_p = model(t_u,w,b) # μλ°©ν–¥ μ „λ‹¬
    loss = loss_fn(t_p,t_c) # μ†μ‹¤ν•¨μ μ •μ
    grad = grad_fn(t_u,t_c,t_p,w,b) # μ—­λ°©ν–¥ μ „λ‹¬

    params = params - learning_rate * grad # νλΌλ―Έν„° μ΅°μ •
    if epoch % 500 == 0:
      print(f'Epoch {epoch}, Loss {float(loss)}')
      print('    Params:', params)
      print('    Grad:  ', grad)
    
  return params
```

ν›λ ¨ λ£¨ν”„λ¥Ό μ •μν–μΌλ‹ ν›λ ¨ λ£¨ν”„λ¥Ό μ •μν•κ³  μ‹¤ν–‰ν•μ.


```python
training_loop(n_epochs=100,  # 100λ² λ°λ³µ
              learning_rate = 1e-2,
              params = torch.tensor([1.0,0.0]), # μ„μλ΅ μ •ν• νλΌλ―Έν„° μ΄κΈ°κ°’
              t_u = t_u,
              t_c = t_c)
```

    Epoch 10, Loss 9.090110518901907e+34
        Params: tensor([3.2144e+17, 5.6621e+15])
        Grad:   tensor([-3.2700e+19, -5.7600e+17])
    Epoch 20, Loss inf
        Params: tensor([1.3457e+35, 2.3704e+33])
        Grad:   tensor([-1.3690e+37, -2.4114e+35])
    Epoch 30, Loss nan
        Params: tensor([nan, nan])
        Grad:   tensor([nan, nan])
    Epoch 40, Loss nan
        Params: tensor([nan, nan])
        Grad:   tensor([nan, nan])
    Epoch 50, Loss nan
        Params: tensor([nan, nan])
        Grad:   tensor([nan, nan])
    Epoch 60, Loss nan
        Params: tensor([nan, nan])
        Grad:   tensor([nan, nan])
    Epoch 70, Loss nan
        Params: tensor([nan, nan])
        Grad:   tensor([nan, nan])
    Epoch 80, Loss nan
        Params: tensor([nan, nan])
        Grad:   tensor([nan, nan])
    Epoch 90, Loss nan
        Params: tensor([nan, nan])
        Grad:   tensor([nan, nan])
    Epoch 100, Loss nan
        Params: tensor([nan, nan])
        Grad:   tensor([nan, nan])





    tensor([nan, nan])



μ΄λ°! μ†μ‹¤κ°’μ΄ ν­λ°ν•λ©΄μ„ λ¬΄ν•λ€(inf)κ°€ λμ—λ‹¤! μ΄κ±΄ params μ΅°μ •μ΄ λ„λ¬΄ ν¬λ‹¤λ” μ‹ νΈμ΄λ©° μ΄λ° κ²½μ° μ΅°μ • κ°’μ΄ μ μ  μ»¤μ§€λ©΄μ„ λ” μ‹¬ν• κ³Όμ‰ κµμ •μΌλ΅ μ΄μ–΄μ§„λ‹¤. κ²°κµ­ μµμ ν™”μ— μλ ΄ν•μ§€ μ•κ³  λ°μ‚°ν•΄ λ²„λ¦°λ‹¤.

![train3](https://user-images.githubusercontent.com/77332628/209425881-34375fcd-0f88-4c13-a310-43f243c9ff06.png)

μ„μ μ΄λ―Έμ§€μ²λΌ learning_rate κ°’(μ΄λ―Έμ§€μ—μ„  Ξ±κ°’)μ΄ λ„λ¬΄ ν¬λ©΄ gradientκ°€ ν­λ°ν•΄λ²„λ¦°λ‹¤. κ·ΈλΌ learning_rateμ„ 1e-4 κ°’μΌλ΅ μ¤„μ—¬μ„ ν•λ² ν›λ ¨μ„ μ§„ν–‰ν•΄λ³΄μ.


```python
training_loop(n_epochs=100,  
              learning_rate = 1e-4, # ν•™μµλ¥  μ΅°μ •
              params = torch.tensor([1.0,0.0]), 
              t_u = t_u,
              t_c = t_c)
```

    Epoch 1, Loss 1763.884765625
        Params: tensor([ 0.5483, -0.0083])
        Grad:   tensor([4517.2964,   82.6000])
    Epoch 2, Loss 323.09051513671875
        Params: tensor([ 0.3623, -0.0118])
        Grad:   tensor([1859.5493,   35.7843])
    Epoch 3, Loss 78.92963409423828
        Params: tensor([ 0.2858, -0.0135])
        Grad:   tensor([765.4666,  16.5122])
    Epoch 4, Loss 37.5528450012207
        Params: tensor([ 0.2543, -0.0143])
        Grad:   tensor([315.0790,   8.5787])
    Epoch 5, Loss 30.540283203125
        Params: tensor([ 0.2413, -0.0149])
        Grad:   tensor([129.6733,   5.3127])
    Epoch 6, Loss 29.351154327392578
        Params: tensor([ 0.2360, -0.0153])
        Grad:   tensor([53.3495,  3.9682])
    Epoch 7, Loss 29.148883819580078
        Params: tensor([ 0.2338, -0.0156])
        Grad:   tensor([21.9304,  3.4148])
    Epoch 8, Loss 29.113847732543945
        Params: tensor([ 0.2329, -0.0159])
        Grad:   tensor([8.9964, 3.1869])
    Epoch 9, Loss 29.107145309448242
        Params: tensor([ 0.2325, -0.0162])
        Grad:   tensor([3.6721, 3.0930])
    Epoch 10, Loss 29.105247497558594
        Params: tensor([ 0.2324, -0.0166])
        Grad:   tensor([1.4803, 3.0544])
    Epoch 20, Loss 29.09588050842285
        Params: tensor([ 0.2323, -0.0196])
        Grad:   tensor([-0.0531,  3.0268])
    Epoch 40, Loss 29.07756233215332
        Params: tensor([ 0.2324, -0.0256])
        Grad:   tensor([-0.0533,  3.0258])
    Epoch 60, Loss 29.059247970581055
        Params: tensor([ 0.2325, -0.0317])
        Grad:   tensor([-0.0533,  3.0247])
    Epoch 80, Loss 29.04095458984375
        Params: tensor([ 0.2326, -0.0377])
        Grad:   tensor([-0.0532,  3.0236])
    Epoch 100, Loss 29.022666931152344
        Params: tensor([ 0.2327, -0.0438])
        Grad:   tensor([-0.0532,  3.0226])





    tensor([ 0.2327, -0.0438])



λ‹¤ν–‰ν ν•™μµλ¥ μ„ μ¤„μ΄λ‹ ν›λ ¨μ΄ μ•μ •μ μΌλ΅ μ΄λ£¨μ–΄μ§€λ” κ²ƒμ„ λ³Ό μ μλ‹¤. ν•μ§€λ§ λ‘κ°€μ§€ λ¬Έμ μ μ΄ μλ‹¤. ν•λ‚λ” νλΌλ―Έν„°μ μ΅°μ •μ΄ λ„λ¬΄ λλ¦¬κ² μ΄λ£¨μ–΄μ§€κ³  μλ‹¤. μ΄λ” learning_rateλ¥Ό μ΅°μ • κ·λ¨μ— λ”°λΌ λ³€ν•λ” μ μ‘ν•μΌλ΅ λ§λ“¤μ–΄μ„ ν•΄κ²°ν•  μ μλ”λ°, λ‚μ¤‘μ— λ‹¤λ£°κ²ƒμ΄λ‹¤. λ‘λ²μ§Έ λ¬Έμ λ” μ μ¬μ μΌλ΅ λ¬Έμ κ°€ λ  λ§ν• κ²ƒμΈλ°, κΈ°μΈκΈ°μ— λ€ν• λ¬Έμ λ‹¤. 

#### 4.1 μ…λ ¥ μ •κ·ν™”

μµμ ν™” μ‘μ—… μ¤‘μ— μ—ν¬ν¬ 1μ—μ„μ gradλ¥Ό κ΄€μ°°ν•΄λ³΄λ©΄ wμ—λ€ν• κΈ°μΈκΈ°κ°€ bμ— λ€ν• κΈ°μΈκΈ°μ— 50λ°°μΈ κ²ƒμ„ λ³Ό μ μλ‹¤. μ¦‰, κ°€μ¤‘μΉμ™€ νΈν–¥κ°’μ λ²”μ„κ°€ λ‹¤λ¥΄λ‹¤λ” κ²ƒμ΄λ‹¤. μ΄λ° κ²½μ°μ— ν•λ‚μ νλΌλ―Έν„°λ¥Ό μ—…λ°μ΄νΈν•κΈ° μ„ν• μ μ ν• ν•™μµλ¥ μ€ λ‹¤λ¥Έ νλΌλ―Έν„°μ μ—…λ°μ΄νΈλ¥Ό λ¶μ•μ •ν•κ² λ§λ“¤ μλ„ μλ‹¤. νλΌλ―Έν„° λ³„λ΅ λ‹¤λ¥Έ ν•™μµλ¥ μ„ μ£Όλ” μ‹μ μ„Έμ„Έν• κ΄€λ¦¬λ¥Ό μ°λ¦¬λ” μ›ν•μ§€ μ•λ”λ‹¤. κ·Έ λ€μ‹ μ— μ…λ ¥κ°’μ„ λ³€κ²½ν•΄μ„ κΈ°μΈκΈ°κ°€ μ„λ΅ ν° μ°¨μ΄κ°€ λ‚μ§€ μ•κ² ν•λ©΄ λ” μ‰½κ² μ μ–΄κ°€ κ°€λ¥ν•λ‹¤! μ…λ ¥ κ°’μ λ²μ„κ°€ -1κ³Ό 1 μ‚¬μ΄λ¥Ό λ²—μ–΄λ‚μ§€ μ•λ„λ΅ λ°”κΏ”λ†“μΌλ©΄ λλ”λ°, μ°λ¦¬ μμ μ—μ„λ” t_uμ— 0.1μ„ κ³±ν•λ©΄ μ μ‚¬ν•κ² μ²λ¦¬κ°€ λλ‹¤.


```python
t_un = 0.1 * t_u # μ •κ·ν™”ν• μ…λ ¥μ λ³€μ λ…μ€ t_un
```

μ •κ·ν™”λ μ…λ ¥μΌλ΅ ν›λ ¨ λ£¨ν”„λ¥Ό λλ ¤λ³΄μ.


```python
training_loop(n_epochs=100,
              learning_rate=1e-2,
              params=torch.tensor([1.0,0.0]),
              t_u = t_un, # μ •κ·ν™”λ μ…λ ¥ μ‚¬μ©
              t_c = t_c)
```

    Epoch 20, Loss 28.157804489135742
        Params: tensor([ 2.3746, -0.3615])
        Grad:   tensor([-0.5093,  2.8832])
    Epoch 40, Loss 26.498987197875977
        Params: tensor([ 2.4747, -0.9280])
        Grad:   tensor([-0.4923,  2.7868])
    Epoch 60, Loss 24.949235916137695
        Params: tensor([ 2.5714, -1.4755])
        Grad:   tensor([-0.4758,  2.6936])
    Epoch 80, Loss 23.501379013061523
        Params: tensor([ 2.6649, -2.0047])
        Grad:   tensor([-0.4599,  2.6035])
    Epoch 100, Loss 22.148710250854492
        Params: tensor([ 2.7553, -2.5162])
        Grad:   tensor([-0.4446,  2.5165])





    tensor([ 2.7553, -2.5162])



ν•™μµλ¥ μ„ 1e-2λ΅ λ‹¤μ‹ λλ ¤λ†”λ„ νλΌλ―Έν„°κ°€ λ°μ‚°ν•μ§€ μ•λ”λ‹¤. Grad κ°’μ„ μ‚΄ν΄λ³΄λ©΄ λ‘ λ‹¤ λΉ„μ·ν• μλ¦Ώμλ΅ μ΄λ¤„μ΅κΈ° λ•λ¬Έμ— λ°μ‚°ν•μ§€ μ•λ” κ²ƒμ΄ κ°€λ¥ν–λ κ²ƒμ΄λ‹¤. 

μ΄μ  ν•™μµλ¥ μ„ λ‹¤μ‹ λλ ΈμΌλ‹ paramsμ λ³€ν™”λ‰μ΄ μ¶©λ¶„ν μ‘μ•„μ§ λ•κΉμ§€ μ—ν¬ν¬μλ¥Ό 5000κΉμ§€ λλ ¤μ„ λ‹¤μ‹ ν›λ ¨ λ£¨ν”„λ¥Ό λλ ¤λ³΄μ.


```python
params = training_loop(n_epochs=5000,
              learning_rate=1e-2,
              params=torch.tensor([1.0,0.0]),
              t_u = t_un,
              t_c = t_c)

```

    Epoch 500, Loss 7.860115051269531
        Params: tensor([ 4.0443, -9.8133])
        Grad:   tensor([-0.2252,  1.2748])
    Epoch 1000, Loss 3.828537940979004
        Params: tensor([  4.8021, -14.1031])
        Grad:   tensor([-0.0962,  0.5448])
    Epoch 1500, Loss 3.092191219329834
        Params: tensor([  5.1260, -15.9365])
        Grad:   tensor([-0.0411,  0.2328])
    Epoch 2000, Loss 2.957697868347168
        Params: tensor([  5.2644, -16.7200])
        Grad:   tensor([-0.0176,  0.0995])
    Epoch 2500, Loss 2.933133840560913
        Params: tensor([  5.3236, -17.0549])
        Grad:   tensor([-0.0075,  0.0425])
    Epoch 3000, Loss 2.9286484718322754
        Params: tensor([  5.3489, -17.1980])
        Grad:   tensor([-0.0032,  0.0182])
    Epoch 3500, Loss 2.9278297424316406
        Params: tensor([  5.3597, -17.2591])
        Grad:   tensor([-0.0014,  0.0078])
    Epoch 4000, Loss 2.927680253982544
        Params: tensor([  5.3643, -17.2853])
        Grad:   tensor([-0.0006,  0.0033])
    Epoch 4500, Loss 2.9276506900787354
        Params: tensor([  5.3662, -17.2964])
        Grad:   tensor([-0.0002,  0.0014])
    Epoch 5000, Loss 2.927647590637207
        Params: tensor([  5.3671, -17.3012])
        Grad:   tensor([-0.0001,  0.0006])


μ†μ‹¤κ°’μ΄ 0κΉμ§€ μ¤„μ§€λ” μ•μ•μ§€λ§ μ΄λ” μ—ν¬ν¬ μκ°€ λ¶€μ΅±ν–κ±°λ‚ , λ°μ΄ν„°κ°€ μ™„μ „ν• μ„ ν• κ΄€κ³„λ¥Ό κ°–μ§€ μ•κ±°λ‚ μ°λ¦¬κ°€ μ¨λ„ λ°μ΄ν„°λ¥Ό λμΌλ΅ μΈ΅μ •ν•λ©΄μ„ μƒκΈ΄ λ…Έμ΄μ¦ λ•λ¬ΈμΌ κ²ƒμ΄λ‹¤. λ§μ§€λ§‰μ— μ¶λ ¥λ νλΌλ―Έν„°λ¥Ό λ³΄λ©΄ μ„­μ”¨ μ¨λ„λ¥Ό ν™”μ”¨λ΅ λ³€ν™ν•λ”λ° ν•„μ”ν• κ°’κ³Ό κ±°μ μΌμΉν•λ‹¤! μ°λ¦¬κ°€ μΈ΅μ •ν• μ¨λ„κ³„λ” ν™”μ”¨ μ¨λ„λ¥Ό λ‚νƒ€λ‚Έλ‹¤λ” κ²ƒμ„ μ•κ² λμ—λ‹¤! 

### 5. μ‹κ°ν™”ν•κΈ°
t_cμ™€ t_uμ κ°’μ„ κ·Έλν”„μ— λ‚νƒ€λ‚΄κ³ , μ°λ¦¬κ°€ μµμ ν™”λ¥Ό ν• νλΌλ―Έν„°λ¥Ό μ…λ ¥ν• μ„ ν• κ·Έλν”„λ¥Ό λ™μ‹μ— κ·Έλ ¤μ„ μ°λ¦¬κ°€ λ§λ“  μ„ ν• λ¨λΈμ΄ λ°μ΄ν„°μ— μ–Όλ§λ‚ μ ν•©ν•μ§€ μ‹κ°ν™”λ¥Ό ν•΄λ³΄μ.


```python
%matplotlib inline
from matplotlib import pyplot as plt

t_p = model(t_un,*params) # *paramsλ” params μ”μ†λ¥Ό κ°λ³„ μΈμλ΅ μ „λ‹¬ν•λ‹¤λ” λ»
fig = plt.figure(dpi=200)
plt.xlabel("Temperature (Β°Fahrenheit)")
plt.ylabel("Temperature (Β°Celsius)")
plt.plot(t_u.numpy(), t_p.detach().numpy()) # μ• μ μ—†λ” μ›λ³Έ κ°’μ„ κ·Έλ ¤λ΄„
plt.plot(t_u.numpy(), t_c.numpy(), 'o')
```




    [<matplotlib.lines.Line2D at 0x7fc85f042610>]




    
![train4](https://user-images.githubusercontent.com/77332628/209425882-390a8fe8-b9b1-49f5-9703-f48c7c7fc174.png)
    


μ΄λ²μ—λ” κ°„λ‹¨ν• μ¨λ„ μμ λ¥Ό ν’€κΈ° μ„ν• κ°„λ‹¨ν• μ„ ν• λ¨λΈμ„ λ§λ“¤κ³  νμ΄ν† μΉλ΅ λ¨λΈμ νλΌλ―Έν„°λ¥Ό μµμ ν™”ν•λ” μ•κ³ λ¦¬μ¦κΉμ§€ λ§λ“¤μ–΄μ„ λ¬Έμ λ¥Ό ν’€μ–΄λ³΄μ•λ‹¤. λ‹¤μ κΈ€μ—μ„ μ΄μ–΄μ„ μ¨λ„ λ¬Έμ λ¥Ό νμ΄ν† μΉλ΅ ν’€μ–΄λ³΄λ„λ΅ ν•κ² λ‹¤.
