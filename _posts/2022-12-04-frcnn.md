---
title : '[DL/CV] 객체 탐지 - Fast RCNN 📦'
layout : single
toc : true
toc: true
toc_sticky: true
categories:
  - cv-objectdetection
---
## Fast RCNN 논문 읽어보기

### 0. 핵심 아이디어

Fast RCNN은 SPPNet의 한계점들을 극복하고자 하는 시도에서 출발한다. SPPNet은 1) end-to-end 구조가 아닌 여러 단계를 거쳐야 하고, 2) SPPNet 뒤의 Fully Connected 층 밖에 학습시키지 못한다는 한계점들이 있었다. 따라서 Fast RCNN은 **"CNN 특징 추출부터, 분류, bounding box regression(BBR)까지 모두 하나의 모델에서 학습킨다."** 라는 아이디어로 시작한다.

![frcnn1](https://user-images.githubusercontent.com/77332628/205485379-88037e19-cce3-4dec-bd10-ee8a25e3d33e.png)

Fast RCNN의 개략적인 알고리즘은 다음과 같다.
1. 전체 이미지를 사전 학습된 CNN에 주입해 피쳐맵을 추출한다.
2. Selective Search를 통해 찾은 각각의 RoI에 RoI Pooling을 적용해서 고정된 크기의 feature vector를 얻는다.
3. Feature vector가 FC 층을 통과한뒤 두개의 과정으로 나뉜다.
4. (a) 하나는 softmax를 통과해서 해당 RoI가 어떤 물체인지 분류하는 과정을 거친다. (SVM 사용 X)
5. (b) 나머지 하나는 BBR을 통해서 RoI의 위치를 조정한다.

### 1. RoI Pooling
CNN을 통과하여 얻은 피쳐맵을 미리 정해놓은 H(높이) x W(너비) 크기에 맞게끔 그리드를 설정하고, 가각의 칸별로 max pooling을 적용하면 항상 HxW 크기의 피쳐맵이 출력된다. 이를 펼쳐서 feature vector를 추출하게 된다. (RoI Poolng은 이전 글에서 봤던 SPP에서 피라미드 레벨이 1인 경우와 동일하다.)

![frcnn2](https://user-images.githubusercontent.com/77332628/205485380-a748b937-9492-4337-866d-bd8711df123e.png)

### 2. Multi Task Loss
RoI Pooling을 통해서 feature vector를 구했다, 이제는 이 벡터로 classification과 bounding box regression을 적용해서 각각의 loss를 얻어내고 이를 역전파하여 전체 모델을 학습시키는 과정이 남았다. 이때 classification과 BBR을 적절하게 엮어주는 loss가 필요한데, 이를 mulit task loss라고 한다. 수식은 아래와 같다.

![frcnn3](https://user-images.githubusercontent.com/77332628/205485381-667f5ce4-7fe7-45e0-b118-f62f83b39412.png)

앞의 두개 p와 u는 classification과 관련된 인자인데, p는 softmax를 통해 얻어낸 K+1개의(K개의 object + 1개의 아무 물체도 아님을 나타내는 클래스) 확률값이고, u는 RoI의 ground truth label 값이다.

![frcnn4](https://user-images.githubusercontent.com/77332628/205485384-1bd6589d-29b0-478e-bcd4-f3235efbc9d3.png)

classification loss는 다음과 같이 log loss를 사용한다.

![frcnn6](https://user-images.githubusercontent.com/77332628/205485386-43284c93-a139-44c3-85fd-3875f770ffd3.png)

그 다음 BBR을 적용하면 K+1개의 클래스에 대해 각각 x,y,w,h를 조정하는 tk값을 리터하는데, 이는 RoI가 특정 클래스일 경우 RoI를 어떻게 조절하라는 값이다. loss에서는 이 값들 가운데 ground truth label에 해당하는 값만 사용하며 이는 3번째 값인 tu이다. 4번째 값인 v는 ground truth bounding box 조절 값에 해당한다. 아래는 tu값에 대한 식이다.

![frcnn5](https://user-images.githubusercontent.com/77332628/205485385-6bac201b-af2e-4f98-b8a8-649a33f1a1e0.png)

BBR을 통해 얻는 loss는 다음과 같이 smoothL1이라는 함수를 사용하는데, 입력으로는 정답 label에 해당하는 BBR 예측값과 ground truth 조절 값을 받는다.

![frcnn7](https://user-images.githubusercontent.com/77332628/205485387-77274b22-0719-44f2-ac92-b29a840b4a92.png)

x,y,w,h 각각에 대해서 예측 값과 정답 값의 차이를 계산한 후 smoothL1 함수를 통과시킨후 합을 계산한다. smoothL1 함수는 다음과 같은데 이를 사용하는 이유는 실험 과정에서 정답 값과 예측값이 지나치게 차이가 많이 나는 이상치가 발생했고, 이들을 그대로 L2 distance(0.5x^2)로 계산하면 gradient가 explode 해버리는 현상을 방지하기 위해 다음과 같은 함수를 사용한 것이라고 한다.

![frcnn8](https://user-images.githubusercontent.com/77332628/205485388-8489468d-2ff8-4c33-a82d-8448d7b553d9.png)

### 3. Backpropagation through RoI Pooling Layer
SPPNet의 한계점을 극복하기 위해 RoI Pooling Layer 이전까지 back propagation을 전달할 수 있는지 이론적으로 검증을 한다. 먼저 다음 수식을 살펴보면,

![frcnn9](https://user-images.githubusercontent.com/77332628/205485390-f3a0c3bf-8c1a-42e1-86e3-641a0c8d943c.png)

xi는 CNN을 통과해 추출된 피쳐 맵에서 하나의 feature 값이고 실수이다. 전체 loss에 대해 xi의 편미분 값을 구하면 그 값이 곧 xi에 대한 loss값이 되며 역전파 알고리즘을 수행할 수 있다. RoI Pooling을 적용하기 위해 HxW 크기의 grid로 나눈다. 이 그리들을 sub-window라고 부르고, 위 수식에서 j란 몇번째 sub-window인지를 나타내는 인덱스다. yjr은 이 RoI Pooling
을 통과해서 최종적으로 얻어진 output 값이며 이 역시 실수다. 이는 다음 이미지와 같다.

![frcnn10](https://user-images.githubusercontent.com/77332628/205485391-9168fdcd-114a-4678-98ec-30406df889cc.png)

xi가 최종 prediction에 영향을 미치려면 xi가 속하는 모든 RoI의 sub-window에서 해당 xi가 최대값이 되야한다(max pooling을 거치기 때문에). i*(r,j)는 RoI와 j가 주어졌을 때 최대 피쳐 값의 인덱스를 말하는 것이며, 이는 곳 RoI Pooling
을 통과하는 인덱스이다. 이 RoI Pooling을 통과한 이후 값에 대한 loss는 이미 전체 loss에 대한 yjr의 편미분 값으로 이미 계산이 되어있기 때문에, 이를 중첩시키기만 하면 xi에 대한 loss를 구할 수 있게 된다.

결론적으로 multitask loss를 RoI Pooling layer를 통과해서 CNN layer까지 fine tuning 할 수 있다. 다음 표를 보면 CNN을 더 깊이 학습시킬수록 성능은 향상되지만 테스트 소요 시간에는 거의 변화가 없는 것을 알 수 있다. 

![frcnn11](https://user-images.githubusercontent.com/77332628/205485393-eb6838e8-b1cc-4a22-bec7-6514e58396df.png)

즉, Object Detection에 맞게끔 CNN 단을 fine tuning 하는 것이 성능 향상에 큰 도움이 된다는 것을 알 수 있다.

### 마무리하며

해당 논문은 object detection 테스크를 푸는 end-to-end 모델을 제시하면서 학습 단계를 간소화시키고 정확도와 성능 모두를 향상시켰다는 의의가 있다. 하지만 여전히 region proposal을 selective search로 수행하고, 이는 CPU 연산으로만 수행 가능하다는 한계점을 극복해야한다.

참고자료 
[1] Ross, Fast R-CNN, 2015

[2] 개인 블로그 (https://yeomko.tistory.com/15)

[3] towardsdatascience, Fast R-CNN for object detection, https://towardsdatascience.com/fast-r-cnn-for-object-detection-a-technical-summary-a0ff94faa022



