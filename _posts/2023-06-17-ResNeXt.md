---
layout: single
title:  "[IC/개념] 이미지 분류 - ResNeXt ⏭️"
toc: true
toc_sticky: true
categories:
  - cv-imageclassification
---

## ResNeXt 논문 리뷰

이번 글에서는 [**<U>ResNeXt 논문</U>**](https://arxiv.org/pdf/1611.05431.pdf)(Aggregated residual transformations for deep neural networks.)을 리뷰해보도록 하겠다.

**이미지 데이터를 다루는 연구들의 방향**이 단순히 Feature를 잘 처리하는 Feature Engineering 뿐만 아니라 **효율적으로 학습이 가능한 Network를 설계하는 Network Engineering으로 전환**됐다.
하지만 설정해야 할 하이퍼파라미터가 점점 늘어남에 따라 연구자들이 여러 Task에 대해서 적절한 하이퍼파라미터를 설정하는 것이 어렵기 때문에 효율적인 Architecture를 설계하는 것은 쉽지 않다.

그래서 **ResNeXt 모델은 ResNet 모델에 Inception 계열의 모델들이 가지는 주요 특성인 Split-Transform-Merge의 특성을 적용한 모델**로, 각 layer 별로 kernel size를 어떻게 설정해야 할지와 같은 고민들로부터 연구자들을 해방시킬 수 있다.

### 1. Split - Transform - Merge

ResNeXt의 핵심은 ResNet 구조에 Inception 계열의 모델에서 사용하던 Cardinality 개념을 도입하여 **Convolution 연산을 쪼개서 진행하고, 서로 다른 Weight를 구한 뒤 합쳐주는 Split-Transform-Merge를 추가**한 것이다.

이미지1

위의 오른쪽 이미지처럼 쪼개진 **CNN이 몇개의 path를 가지는지를 결정하는 파라미터가 바로 Cardinality**이며, **각각의 path에서 가지는 채널을 depth**라고 정의한다. 따라서 위의 예시는 Cardinality=32, depth=4의 ResNeXt (32x4d)로 정의된다.

같은 깊이의 ResNet과 비교해보면 다음과 같다.

이미지2


### 2. ResNeXt architecture

ResNeXt는 ResNet의 Template는 그대로 사용하고 Design만 바꾼다. 자세한 구조의 위 표와 같다.

ResNeXt를 구현하는 모델링 방법으로 세가지 방법을 제시했는데, 세 방법 모두 성능은 같다고 한다. 논문에서는 구현하기 쉽고 빠른 (b)를 사용했다고 한다. (c)에서의 group의 개수가 cardinality이다.

이미지3

ResNext의 블록 내 연산 과정은 Weighted Sum 연산과정과 매우 비슷하다. 입력 데이터가 **x** = $[x_1,x_2,...,x_D]$이고 (D채널 입력 벡터), $W_i$를 $i$번째 Conv layer라고 한다면, ResNeXt 모듈 내 연산은 $Σ^D_{i=1}W_ix_i$가 된다.

이미지4

위 연산은 세가지 단계로 나눠서 생각할 수 있다.

1) Splitting : **X**가 낮은 차원으로 임베딩 된다. (1x1 Conv 연산에 의해 채널 수 축소)

2) Transforming : 낮은 차원의 벡터가 $W_ix_i$로 변환된다. (3x3 Conv 연산에 의해 feature map 연산을 진행)

3) Aggregating : 변환된 결과가 하나로 합쳐진다. (3x3 Conv 연산 결과들을 concatenate)



### 3. Experiments on ImageNet-1k

1) Cardinality vs Width

고정된 Complexity를 갖는 모델에서 cardinality와 width의 trade-off를 평가하는 실험이다. 다음과 같이 cardinality가 증가할수록 성능이 높아졌다. 또한 ResNet-50보다 ResNeXt-50의 학습이 더욱 빠르게 진행됐다.

이미지5

이미지6

2) Increasing Cardinality vs Deeper/Wider

이미지7

위 표에서 보이다시피 ResNext-101의 성능이 가장 높았다. 따라서 성능향상에 중요한 순서로는 cardinality > width > deep이라고 할 수 있다.


출처 및 참고문헌 :

1. https://arxiv.org/pdf/1611.05431.pdf

2. https://imlim0813.tistory.com/40

3. https://cryptosalamander.tistory.com/159
