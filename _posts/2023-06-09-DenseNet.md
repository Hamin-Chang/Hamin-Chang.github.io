---
layout: single
title:  "[IC/개념] 이미지 분류 - DenseNet 🕸️"
toc: true
toc_sticky: true
categories:
  - cv-imageclassification
---

## DenseNet 논문 리뷰

이번 글에서는 [**<U>DenseNet 논문</U>**](https://arxiv.org/pdf/1608.06993.pdf)(Densenet, Densely Connected Convolutional Networks)을 리뷰한다.

### 1. Introduction

당시 CNN 모델들의 깊이가 더 깊어지면서 새로운 연구 문제가 발생했다. 따라서 ResNet와 같이 input layer와 output layer가 direct하게 연결될 수 있는 shorter connection 개념에 집중하여 효율적으로 train하는 방식으로 발전하고 있다.

이 논문에서는 네트워크 층 간의 정보 흐름을 극대화하기 위해서 **모든 층을 서로 직접 연결하는 방식을 제안**한다. feed-forward 본질을 보존하기 위해 각 층은 선행하는 층들로부터 추가적인 input을 얻고, 자체 특성맵을 이후의 모든 층에 전달한다. ResNet과는 달리 feature가 층으로 전달되기 전에 합산을 통해 feature를 결합하지 않고, **concatenation을 사용해서 연결**한다는 것이다. 따라서 **$L$번째 층의 feature map은 이후 $L-1$개의 모든 층을 통과**한다. 이 과정으로 인해 $L$-layer network에는 전통적인 구조가 $L$개의 연결이 존재하는 반면에 **DenseNet에서는 $(L(L+1))/2$개의 연결이 존재**하게 된다.

![1](https://github.com/Hamin-Chang/Hamin-Chang.github.io/assets/77332628/e7f6066d-a8c3-4f04-8444-cd36c1515a48)

이러한 DenseNet은 다음의 장점들을 갖는다.

1. vanishing gradient 방지
2. feature propagation 강화
3. feature reuse 권장
4. parameter 수 감소

### 2. Connectivity

그럼 ResNet과 DenseNet의 연결이 서로 어떻게 다른지 알아보자.

먼저 ResNet의 connectivity 식을 보면 다음과 같다.

![2](https://github.com/Hamin-Chang/Hamin-Chang.github.io/assets/77332628/48717c53-e053-4ed5-8c9a-1f8af7e979dd)

$H_l(x_{l-1})$은 conv, bn, relu 함수의 연산을 의미하고 $+x_{l-1}$은 skip connection에 의한 덧셈이다. 이 경우에 layer의 입력값이 출력값에 더해져 gradient flow가 직접적으로 전달되는데, **덧셈으로 결합되기 때문에 신경망에서 정보흐름이 지연**될 수 있다고 한다.

다음은 DenseNet의 connectivity 식은 다음과 같다.

![3](https://github.com/Hamin-Chang/Hamin-Chang.github.io/assets/77332628/3b0c0dab-3217-460b-80bb-81fe5714c0f7)

DenseNet은 **이전 layer를 모든 다음 layer에 concatenation을 통해서 연결하기 때문에 정보 흐름이 향상**된다고 한다. 

두 connectivity를 그림으로 비교하면 다음과 같다.

![4](https://github.com/Hamin-Chang/Hamin-Chang.github.io/assets/77332628/b7cc2b89-5dec-428c-b9c2-61613ad93ef4)

왼쪽은 ResNet연결이고, 오른쪽은 DenseNet연결이다.

둘 다 basic block이라고 가정했을 때, resnet은 input과 output의 channel이 같지만, **DenseNet은 output feature map의 channel이 더 커진다**. 



### 3. Dense Block의 구조

![5](https://github.com/Hamin-Chang/Hamin-Chang.github.io/assets/77332628/9f0edb8a-a5bf-408c-a0aa-b4e061164d22)

Dense Block의 구조는 위 이미지와 같다.

2)에서 다룬 Dense Connection 방식을 사용하여 각 layer를 연결하는데, 여기서 **각 dense block에서 몇 개의 feature map을 뽑을 지 결정하는 하이퍼파라미터 Growth rate $k$**는, 모델의 파라미터의 수에 직접적인 영향을 갖는다. 위 figure 1의 경우 $k=4$를 예로 든 것을 알 수 있다. 원래는 깊이가 깊어질수록 conv block 한번에 상당히 많은 개수의 feature map을 뽑지만, 논문에서는 block마다 $k=12$로 설정하여 아주 효율적인 구조라고 설명한다.

ResNet과 마찬가지로 **반드시 같은 사이즈의 feature map끼리 connection이 가능**하고, 마지막 **Dense block으로 output이 나오면 figure 1 끝에 보이는 Transition layer로 진입**한다.

Transition layer는 (1x1 conv -> 2x2 avgPooling(stride=2))로 구성돼있다. **Dense block에서는 down sampling이 불가능하기 때문에 1x1 conv로 일단 feature들을 한번 정리해주고, avgPooling을 통해 반으로 size를 줄이는 역할**을 한다.

$θ$라는 $0<θ≤1$ 값의 하이퍼파라미터가 존재하는데, Dense block에서 $m$개의 feature map을 받았다면, transition layer가 출력하는 feature map 개수를 조정하는 인자로, $m$ x $θ$로 출력 channel을 조정한다. 즉, **transition layer는 feature map의 크기와 channel 수를 감소시키는 역할**을 하는 것이다. 논문에서는 $θ=0.5$로 두고 실험을 진행했다고 한다.

### 4. DenseNet의 구조

Dense block과 Transition layer를 결합하여 최종적으로 다음과 같은 DenseNet architecture가 만들어진다.

![6](https://github.com/Hamin-Chang/Hamin-Chang.github.io/assets/77332628/4703ab41-c24a-498f-8677-8a758902496f)

ImageNet 데이터셋은 스케일이 굉장히 크기 때문에 다음 table 1의 architecture로 실험을 진행했다.

![7](https://github.com/Hamin-Chang/Hamin-Chang.github.io/assets/77332628/2d64739a-1836-4d07-afa1-4274929b7648)

DenseNet-121을 보면, growth rate $k$를 32로 설정하고, 각 dense block마다 conv block이 2개씩 있기 때문에 layer 수를 세보면, 2 x (6 + 12 + 24 + 16) = 116 layer에 가장 상단의 7x7 conv layer 1개와 transition layer의 1x1 conv layer 3개와 최하단의 1000D fc layer 1개까지 해서 121 layer architecture임을 알 수 있다.

또한 ResNet과 파라미터 수와 성능을 비교했을 때 더 적은 파라미터 수와 좋은 성능을 보이는 것을 알 수 있다.

![8](https://github.com/Hamin-Chang/Hamin-Chang.github.io/assets/77332628/527d0c2c-88df-4a9d-a8e6-93f5ec220d00)

![9](https://github.com/Hamin-Chang/Hamin-Chang.github.io/assets/77332628/0ab6ff66-a757-41e3-a402-d3548beaf3c9)

출처 및 참고문헌:

1. https://arxiv.org/pdf/1608.06993.pdf
2. https://deep-learning-study.tistory.com/528
3. https://csm-kr.tistory.com/10



